<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>413306</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      overflow-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
      overflow-wrap: normal;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      {   }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span.al { color: #ff0000; font-weight: bold; } /* Alert */
    code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
    code span.at { color: #7d9029; } /* Attribute */
    code span.bn { color: #40a070; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #4070a0; } /* Char */
    code span.cn { color: #880000; } /* Constant */
    code span.co { color: #60a0b0; font-style: italic; } /* Comment */
    code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
    code span.do { color: #ba2121; font-style: italic; } /* Documentation */
    code span.dt { color: #902000; } /* DataType */
    code span.dv { color: #40a070; } /* DecVal */
    code span.er { color: #ff0000; font-weight: bold; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #40a070; } /* Float */
    code span.fu { color: #06287e; } /* Function */
    code span.im { } /* Import */
    code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
    code span.kw { color: #007020; font-weight: bold; } /* Keyword */
    code span.op { color: #666666; } /* Operator */
    code span.ot { color: #007020; } /* Other */
    code span.pp { color: #bc7a00; } /* Preprocessor */
    code span.sc { color: #4070a0; } /* SpecialChar */
    code span.ss { color: #bb6688; } /* SpecialString */
    code span.st { color: #4070a0; } /* String */
    code span.va { color: #19177c; } /* Variable */
    code span.vs { color: #4070a0; } /* VerbatimString */
    code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<div class="cell code" id="36215ee6">
<div class="sourceCode" id="cb1"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.init <span class="im">as</span> init</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.nn <span class="im">import</span> functional <span class="im">as</span> F</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.transforms <span class="im">as</span> transforms</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torchvision.models <span class="im">as</span> models</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.transforms <span class="im">import</span> Resize, Normalize, ToTensor, Compose, RandomHorizontalFlip</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.utils.data <span class="im">import</span> DataLoader, Dataset</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision.datasets <span class="im">import</span> CIFAR10</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchsummary <span class="im">import</span> summary</span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tabulate <span class="im">import</span> tabulate</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> tqdm <span class="im">import</span> tqdm</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score</span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> IPython.display <span class="im">import</span> clear_output</span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> urllib.request</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> urllib.parse <span class="im">import</span> urlencode</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> shutil</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> zipfile</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lion_pytorch <span class="im">import</span> Lion</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torch.optim <span class="im">import</span> lr_scheduler</span></code></pre></div>
</div>
<section id="загрузка-данных" class="cell markdown" id="4054f3e8">
<h3>Загрузка данных.</h3>
</section>
<div class="cell code" id="160a84e9" data-outputId="d7a664d5-1f08-4393-d070-794d54a88cd9">
<div class="sourceCode" id="cb2"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>batch_size <span class="op">=</span> <span class="dv">32</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>    transforms.ToTensor(),</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> CIFAR10(root<span class="op">=</span><span class="st">&#39;./data&#39;</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(train_dataset, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> CIFAR10(root<span class="op">=</span><span class="st">&#39;./data&#39;</span>, train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>test_loader <span class="op">=</span> DataLoader(test_dataset, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Files already downloaded and verified
Files already downloaded and verified
</code></pre>
</div>
</div>
<div class="cell code" id="e7e38543" data-outputId="87c1df00-a37f-4cab-95af-b6d83855a297">
<div class="sourceCode" id="cb4"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Размер обучающей выборки: </span><span class="sc">{</span><span class="bu">len</span>(train_dataset)<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f&#39;Размер тестовой выборки: </span><span class="sc">{</span><span class="bu">len</span>(test_dataset)<span class="sc">}</span><span class="ss">&#39;</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&#39;</span><span class="ch">\n</span><span class="st">Классы:&#39;</span>)</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(tabulate(</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    <span class="bu">list</span>(train_dataset.class_to_idx.items()), headers<span class="op">=</span>[<span class="st">&#39;Название&#39;</span>, <span class="st">&#39;Индекс&#39;</span>],</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    tablefmt<span class="op">=</span><span class="st">&#39;pretty&#39;</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Размер обучающей выборки: 50000
Размер тестовой выборки: 10000

Классы:
+------------+--------+
|  Название  | Индекс |
+------------+--------+
|  airplane  |   0    |
| automobile |   1    |
|    bird    |   2    |
|    cat     |   3    |
|    deer    |   4    |
|    dog     |   5    |
|    frog    |   6    |
|   horse    |   7    |
|    ship    |   8    |
|   truck    |   9    |
+------------+--------+
</code></pre>
</div>
</div>
<div class="cell code" id="403a8e9e" data-outputId="23d1c4c3-b646-4aca-ce44-c851100fbd6a">
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>index_to_label <span class="op">=</span> {v: k <span class="cf">for</span> k, v <span class="kw">in</span> train_dataset.class_to_idx.items()}</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">6</span>))</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>class_labels_train <span class="op">=</span> [index_to_label[idx] <span class="cf">for</span> idx <span class="kw">in</span> train_dataset.targets]</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>unique_labels_train <span class="op">=</span> <span class="bu">list</span>(index_to_label.values())</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>sns.countplot(x<span class="op">=</span>class_labels_train, order<span class="op">=</span>unique_labels_train)</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Распределение классов в обучающей выборке&#39;</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">&#39;right&#39;</span>)</span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>fig, ax <span class="op">=</span> plt.subplots(figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">6</span>))</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>class_labels_test <span class="op">=</span> [index_to_label[idx] <span class="cf">for</span> idx <span class="kw">in</span> test_dataset.targets]</span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a>unique_labels_test <span class="op">=</span> <span class="bu">list</span>(index_to_label.values())</span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a>sns.countplot(x<span class="op">=</span>class_labels_test, order<span class="op">=</span>unique_labels_test)</span>
<span id="cb6-19"><a href="#cb6-19" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Распределение классов в тестовой выборке&#39;</span>)</span>
<span id="cb6-20"><a href="#cb6-20" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">&#39;right&#39;</span>)</span>
<span id="cb6-21"><a href="#cb6-21" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output stream stderr">
<pre><code>C:\Users\User\AppData\Roaming\Python\Python39\site-packages\seaborn\_core.py:1225: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead
  if pd.api.types.is_categorical_dtype(vector):
C:\Users\User\AppData\Roaming\Python\Python39\site-packages\seaborn\_core.py:1225: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead
  if pd.api.types.is_categorical_dtype(vector):
</code></pre>
</div>
<div class="output display_data">
<p><img src="7d5f3375e1a57697cb8b36bf477b5a576c670b68.png" /></p>
</div>
<div class="output stream stderr">
<pre><code>C:\Users\User\AppData\Roaming\Python\Python39\site-packages\seaborn\_core.py:1225: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead
  if pd.api.types.is_categorical_dtype(vector):
C:\Users\User\AppData\Roaming\Python\Python39\site-packages\seaborn\_core.py:1225: FutureWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, CategoricalDtype) instead
  if pd.api.types.is_categorical_dtype(vector):
</code></pre>
</div>
<div class="output display_data">
<p><img src="2409b5a452afbb6c4aa5195458f84067658e52bd.png" /></p>
</div>
</div>
<div class="cell code" id="dd290573" data-outputId="e5e7b367-3838-4947-b846-1894f2004f10">
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>class_names <span class="op">=</span> test_dataset.classes</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> show_images(images, labels):</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>    plt.figure(figsize<span class="op">=</span>(<span class="dv">15</span>, <span class="dv">6</span>))</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">10</span>):</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>        plt.subplot(<span class="dv">2</span>, <span class="dv">5</span>, i <span class="op">+</span> <span class="dv">1</span>)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>        plt.title(class_names[labels[i]])</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>        plt.imshow(np.clip(np.transpose(images[i], (<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">0</span>)), <span class="dv">0</span>, <span class="dv">1</span>))</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>        plt.axis(<span class="st">&#39;off&#39;</span>)</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>data_loader <span class="op">=</span> DataLoader(test_dataset, batch_size<span class="op">=</span><span class="dv">10</span>, shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>data_iter <span class="op">=</span> <span class="bu">iter</span>(data_loader)</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>images, labels <span class="op">=</span> <span class="bu">next</span>(data_iter)</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>show_images(images, labels)</span></code></pre></div>
<div class="output display_data">
<p><img src="a3eb057d68044e2cb635e88a960b0ff36f8e838c.png" /></p>
</div>
</div>
<div class="cell markdown" id="6b8be3b3">
<p><strong>Вывод</strong>:</p>
<ol>
<li>Мы имеем 50 000 в обучающей выборки и 10 000 в тестовой</li>
<li>В каждом классе одинаковое количество классов, дисбаланса не наблюдается</li>
<li>Изображения полностью соответствуют меткам класса</li>
</ol>
</div>
<section id="построение-архитектуры-сверточной-сети" class="cell markdown" id="e5b3be49">
<h3>Построение архитектуры сверточной сети.</h3>
<h4 id="требуется-вывести-информацию-об-архитектуре-опционально-выполнить-визуализацию-сети">Требуется вывести информацию об архитектуре, опционально выполнить визуализацию сети.</h4>
</section>
<div class="cell code" id="0fed2e8e" data-outputId="7d79e526-35ec-431d-c83e-9d517f8501e0">
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>width <span class="op">=</span> <span class="dv">224</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>height <span class="op">=</span> <span class="dv">224</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>transform <span class="op">=</span> transforms.Compose([Resize((width,height)),</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>                                transforms.ToTensor()])</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>cifar10_train <span class="op">=</span> CIFAR10(root<span class="op">=</span><span class="st">&quot;./data&quot;</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>transform)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> DataLoader(cifar10_train, batch_size<span class="op">=</span><span class="dv">256</span>, shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>mean <span class="op">=</span> <span class="fl">0.</span></span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>std <span class="op">=</span> <span class="fl">0.</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>total_samples <span class="op">=</span> <span class="fl">0.</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> data, _ <span class="kw">in</span> train_loader:</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>    batch_samples <span class="op">=</span> data.size(<span class="dv">0</span>)</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>    data <span class="op">=</span> data.view(batch_samples, data.size(<span class="dv">1</span>), <span class="op">-</span><span class="dv">1</span>)</span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>    mean <span class="op">+=</span> data.mean(<span class="dv">2</span>).<span class="bu">sum</span>(<span class="dv">0</span>)</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>    std <span class="op">+=</span> data.std(<span class="dv">2</span>).<span class="bu">sum</span>(<span class="dv">0</span>)</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>    total_samples <span class="op">+=</span> batch_samples</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>mean <span class="op">/=</span> total_samples</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>std <span class="op">/=</span> total_samples</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Mean:&quot;</span>, mean.tolist())</span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">&quot;Std:&quot;</span>, std.tolist())</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Files already downloaded and verified
Mean: [0.4913995563983917, 0.48215848207473755, 0.44653093814849854]
Std: [0.19525285065174103, 0.19247294962406158, 0.1941993534564972]
</code></pre>
</div>
</div>
<div class="cell code" id="6d6e8da5" data-outputId="78502157-6192-4143-a142-22885b61e894">
<div class="sourceCode" id="cb12"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>train_transform <span class="op">=</span> transforms.Compose(</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    [</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>        Resize((width,height)),</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>        transforms.ToTensor(),</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>        transforms.RandomHorizontalFlip(),</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>        transforms.RandomRotation(degrees<span class="op">=</span><span class="dv">15</span>),</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>        transforms.Normalize(mean, std)</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>test_transform <span class="op">=</span> torchvision.transforms.Compose(</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    [</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>        Resize((width,height)),</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>        transforms.ToTensor(),</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>        transforms.Normalize(mean, std)</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a>train_dataset <span class="op">=</span> CIFAR10(root<span class="op">=</span><span class="st">&#39;./data&#39;</span>, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>train_transform)</span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>test_dataset <span class="op">=</span> CIFAR10(root<span class="op">=</span><span class="st">&#39;./data&#39;</span>, train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>, transform<span class="op">=</span>test_transform)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Files already downloaded and verified
Files already downloaded and verified
</code></pre>
</div>
</div>
<div class="cell code" id="c90d2a8e">
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> CustomEarlyStopping():</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, patience<span class="op">=</span><span class="dv">5</span>, min_delta<span class="op">=</span><span class="dv">0</span>, path<span class="op">=</span><span class="st">&quot;best_model.pt&quot;</span>, path_model<span class="op">=</span><span class="st">&quot;best_model&quot;</span>):</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.patience <span class="op">=</span> patience</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.min_delta <span class="op">=</span> min_delta</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.best_accuracy <span class="op">=</span> <span class="va">None</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.early_stop <span class="op">=</span> <span class="va">False</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.path <span class="op">=</span> path</span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.path_model <span class="op">=</span> path_model</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__call__</span>(<span class="va">self</span>, test_accuracy, model, optimizer):</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="va">self</span>.best_accuracy <span class="kw">is</span> <span class="va">None</span>:</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.best_accuracy <span class="op">=</span> test_accuracy</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>            torch.save({</span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;model_state_dict&#39;</span>: model.state_dict(),</span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;optimizer_state_dict&#39;</span>: optimizer.state_dict(),</span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>                <span class="st">&#39;best_accuracy&#39;</span>: test_accuracy,}, <span class="va">self</span>.path)</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>            torch.save(model, <span class="va">self</span>.path_model)</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> test_accuracy <span class="op">-</span> <span class="va">self</span>.best_accuracy <span class="op">&gt;</span> <span class="va">self</span>.min_delta:</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.best_accuracy <span class="op">=</span> test_accuracy</span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.counter <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> os.path.exists(<span class="va">self</span>.path):</span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a>                checkpoint <span class="op">=</span> torch.load(<span class="va">self</span>.path)</span>
<span id="cb14-25"><a href="#cb14-25" aria-hidden="true" tabindex="-1"></a>                <span class="cf">if</span> test_accuracy <span class="op">&gt;</span> checkpoint[<span class="st">&#39;best_accuracy&#39;</span>]:</span>
<span id="cb14-26"><a href="#cb14-26" aria-hidden="true" tabindex="-1"></a>                    torch.save({</span>
<span id="cb14-27"><a href="#cb14-27" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&#39;model_state_dict&#39;</span>: model.state_dict(),</span>
<span id="cb14-28"><a href="#cb14-28" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&#39;optimizer_state_dict&#39;</span>: optimizer.state_dict(),</span>
<span id="cb14-29"><a href="#cb14-29" aria-hidden="true" tabindex="-1"></a>                        <span class="st">&#39;best_accuracy&#39;</span>: test_accuracy,</span>
<span id="cb14-30"><a href="#cb14-30" aria-hidden="true" tabindex="-1"></a>                    }, <span class="va">self</span>.path)</span>
<span id="cb14-31"><a href="#cb14-31" aria-hidden="true" tabindex="-1"></a>                    torch.save(model, <span class="va">self</span>.path_model)</span>
<span id="cb14-32"><a href="#cb14-32" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb14-33"><a href="#cb14-33" aria-hidden="true" tabindex="-1"></a>                torch.save({</span>
<span id="cb14-34"><a href="#cb14-34" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&#39;model_state_dict&#39;</span>: model.state_dict(),</span>
<span id="cb14-35"><a href="#cb14-35" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&#39;optimizer_state_dict&#39;</span>: optimizer.state_dict(),</span>
<span id="cb14-36"><a href="#cb14-36" aria-hidden="true" tabindex="-1"></a>                    <span class="st">&#39;best_accuracy&#39;</span>: test_accuracy,</span>
<span id="cb14-37"><a href="#cb14-37" aria-hidden="true" tabindex="-1"></a>                }, <span class="va">self</span>.path)</span>
<span id="cb14-38"><a href="#cb14-38" aria-hidden="true" tabindex="-1"></a>                torch.save(model, <span class="va">self</span>.path_model)</span>
<span id="cb14-39"><a href="#cb14-39" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> test_accuracy <span class="op">-</span> <span class="va">self</span>.best_accuracy <span class="op">&lt;</span> <span class="va">self</span>.min_delta:</span>
<span id="cb14-40"><a href="#cb14-40" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.counter <span class="op">+=</span> <span class="dv">1</span></span>
<span id="cb14-41"><a href="#cb14-41" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;INFO: Early stopping counter </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>counter<span class="sc">}</span><span class="ss"> of </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>patience<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb14-42"><a href="#cb14-42" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&quot;Best accuracy </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>best_accuracy<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb14-43"><a href="#cb14-43" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="va">self</span>.counter <span class="op">&gt;=</span> <span class="va">self</span>.patience:</span>
<span id="cb14-44"><a href="#cb14-44" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="st">&#39;INFO: Early stopping&#39;</span>)</span>
<span id="cb14-45"><a href="#cb14-45" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.early_stop <span class="op">=</span> <span class="va">True</span></span></code></pre></div>
</div>
<div class="cell code" id="11c513e0">
<div class="sourceCode" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ClassificationTrainer:</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, model: nn.Module, name_optimizer: <span class="bu">str</span>, scheduler: <span class="bu">bool</span>, train_dataset: Dataset,</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>                 test_dataset: Dataset, batch_size:<span class="bu">int</span>, learning_rate: <span class="bu">float</span>, num_epochs: <span class="bu">int</span>,</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>                 coef<span class="op">=</span><span class="fl">0.85</span>, step_size<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model <span class="op">=</span> model</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.train_loader <span class="op">=</span> DataLoader(train_dataset, batch_size<span class="op">=</span>batch_size, shuffle<span class="op">=</span><span class="va">True</span>, num_workers<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.test_loader <span class="op">=</span> DataLoader(test_dataset, batch_size<span class="op">=</span>batch_size, num_workers<span class="op">=</span><span class="dv">0</span>)</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.learning_rate <span class="op">=</span> learning_rate</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.num_epochs <span class="op">=</span> num_epochs</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.criterion <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> name_optimizer <span class="op">==</span> <span class="st">&#39;Lion&#39;</span>:</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.optimizer <span class="op">=</span> Lion(<span class="va">self</span>.model.parameters(), lr<span class="op">=</span>learning_rate, weight_decay<span class="op">=</span><span class="fl">1e-2</span>)</span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a>        <span class="cf">elif</span> name_optimizer <span class="op">==</span> <span class="st">&#39;AdamW&#39;</span>:</span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.optimizer <span class="op">=</span> optim.AdamW(<span class="va">self</span>.model.parameters(), lr<span class="op">=</span>learning_rate)</span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a>            <span class="cf">raise</span> <span class="pp">NotImplementedError</span>()</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> scheduler:</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.scheduler <span class="op">=</span> lr_scheduler.StepLR(<span class="va">self</span>.optimizer, step_size<span class="op">=</span>step_size, gamma<span class="op">=</span>coef)</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.scheduler <span class="op">=</span> <span class="va">None</span></span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.device <span class="op">=</span> torch.device(<span class="st">&quot;cuda:0&quot;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span>)</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.path <span class="op">=</span> <span class="bu">str</span>(<span class="bu">type</span>(<span class="va">self</span>.model).<span class="va">__name__</span>) <span class="op">+</span> <span class="st">&#39;_&#39;</span> <span class="op">+</span> <span class="bu">str</span>(<span class="bu">type</span>(<span class="va">self</span>.optimizer).<span class="va">__name__</span>) <span class="op">+</span> <span class="st">&quot;.pt&quot;</span></span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.path_model <span class="op">=</span><span class="bu">str</span>(<span class="bu">type</span>(<span class="va">self</span>.model).<span class="va">__name__</span>) <span class="op">+</span> <span class="st">&#39;_&#39;</span> <span class="op">+</span> <span class="bu">str</span>(<span class="bu">type</span>(<span class="va">self</span>.optimizer).<span class="va">__name__</span>)</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.losses <span class="op">=</span> {<span class="st">&#39;train&#39;</span>: [], <span class="st">&#39;test&#39;</span>: []}</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.accuracies <span class="op">=</span> {<span class="st">&#39;train&#39;</span>: [], <span class="st">&#39;test&#39;</span>: []}</span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> train_one_epoch(<span class="va">self</span>):</span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model.to(<span class="va">self</span>.device).train()</span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a>        epoch_loss <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a>        epoch_accuracy <span class="op">=</span> <span class="dv">0</span></span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> tqdm(total<span class="op">=</span><span class="bu">len</span>(<span class="va">self</span>.train_loader)) <span class="im">as</span> pbar:</span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> i, batch <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="va">self</span>.train_loader):</span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a>                inputs, labels <span class="op">=</span> batch</span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a>                inputs, labels <span class="op">=</span> inputs.to(<span class="va">self</span>.device), labels.to(<span class="va">self</span>.device)</span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-41"><a href="#cb15-41" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.optimizer.zero_grad()</span>
<span id="cb15-42"><a href="#cb15-42" aria-hidden="true" tabindex="-1"></a>                output <span class="op">=</span> <span class="va">self</span>.model(inputs)</span>
<span id="cb15-43"><a href="#cb15-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-44"><a href="#cb15-44" aria-hidden="true" tabindex="-1"></a>                loss <span class="op">=</span> <span class="va">self</span>.criterion(output, labels)</span>
<span id="cb15-45"><a href="#cb15-45" aria-hidden="true" tabindex="-1"></a>                loss.backward()</span>
<span id="cb15-46"><a href="#cb15-46" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.optimizer.step()</span>
<span id="cb15-47"><a href="#cb15-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-48"><a href="#cb15-48" aria-hidden="true" tabindex="-1"></a>                _, predicted <span class="op">=</span> torch.<span class="bu">max</span>(output.detach(), <span class="dv">1</span>)</span>
<span id="cb15-49"><a href="#cb15-49" aria-hidden="true" tabindex="-1"></a>                accuracy <span class="op">=</span> accuracy_score(predicted.cpu().numpy(), labels.cpu().numpy())</span>
<span id="cb15-50"><a href="#cb15-50" aria-hidden="true" tabindex="-1"></a>                epoch_accuracy <span class="op">+=</span> accuracy</span>
<span id="cb15-51"><a href="#cb15-51" aria-hidden="true" tabindex="-1"></a>                epoch_loss <span class="op">+=</span> loss.item()</span>
<span id="cb15-52"><a href="#cb15-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-53"><a href="#cb15-53" aria-hidden="true" tabindex="-1"></a>                pbar.set_description(<span class="ss">f&#39;Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">; Accuracy: </span><span class="sc">{</span>accuracy<span class="sc">:.4f}</span><span class="ss">&#39;</span>)</span>
<span id="cb15-54"><a href="#cb15-54" aria-hidden="true" tabindex="-1"></a>                pbar.update()</span>
<span id="cb15-55"><a href="#cb15-55" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-56"><a href="#cb15-56" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.losses[<span class="st">&#39;train&#39;</span>].append(epoch_loss <span class="op">/</span> <span class="bu">len</span>(<span class="va">self</span>.train_loader))</span>
<span id="cb15-57"><a href="#cb15-57" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.accuracies[<span class="st">&#39;train&#39;</span>].append(epoch_accuracy <span class="op">/</span> <span class="bu">len</span>(<span class="va">self</span>.train_loader))</span>
<span id="cb15-58"><a href="#cb15-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-59"><a href="#cb15-59" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> validate(<span class="va">self</span>):</span>
<span id="cb15-60"><a href="#cb15-60" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.model.to(<span class="va">self</span>.device).<span class="bu">eval</span>()</span>
<span id="cb15-61"><a href="#cb15-61" aria-hidden="true" tabindex="-1"></a>        losses <span class="op">=</span> []</span>
<span id="cb15-62"><a href="#cb15-62" aria-hidden="true" tabindex="-1"></a>        predicted_classes <span class="op">=</span> []</span>
<span id="cb15-63"><a href="#cb15-63" aria-hidden="true" tabindex="-1"></a>        true_classes <span class="op">=</span> []</span>
<span id="cb15-64"><a href="#cb15-64" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> tqdm(total<span class="op">=</span><span class="bu">len</span>(<span class="va">self</span>.test_loader)) <span class="im">as</span> pbar:</span>
<span id="cb15-65"><a href="#cb15-65" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> torch.no_grad():</span>
<span id="cb15-66"><a href="#cb15-66" aria-hidden="true" tabindex="-1"></a>                <span class="cf">for</span> i, batch <span class="kw">in</span> <span class="bu">enumerate</span>(<span class="va">self</span>.test_loader):</span>
<span id="cb15-67"><a href="#cb15-67" aria-hidden="true" tabindex="-1"></a>                    inputs, labels <span class="op">=</span> batch</span>
<span id="cb15-68"><a href="#cb15-68" aria-hidden="true" tabindex="-1"></a>                    inputs, labels <span class="op">=</span> inputs.to(<span class="va">self</span>.device), labels.to(<span class="va">self</span>.device)</span>
<span id="cb15-69"><a href="#cb15-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-70"><a href="#cb15-70" aria-hidden="true" tabindex="-1"></a>                    <span class="va">self</span>.optimizer.zero_grad()</span>
<span id="cb15-71"><a href="#cb15-71" aria-hidden="true" tabindex="-1"></a>                    output <span class="op">=</span> <span class="va">self</span>.model(inputs)</span>
<span id="cb15-72"><a href="#cb15-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-73"><a href="#cb15-73" aria-hidden="true" tabindex="-1"></a>                    loss <span class="op">=</span> <span class="va">self</span>.criterion(output, labels)</span>
<span id="cb15-74"><a href="#cb15-74" aria-hidden="true" tabindex="-1"></a>                    losses.append(loss.item())</span>
<span id="cb15-75"><a href="#cb15-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-76"><a href="#cb15-76" aria-hidden="true" tabindex="-1"></a>                    _, predicted <span class="op">=</span> torch.<span class="bu">max</span>(output.detach(), <span class="dv">1</span>)</span>
<span id="cb15-77"><a href="#cb15-77" aria-hidden="true" tabindex="-1"></a>                    predicted_classes.append(predicted)</span>
<span id="cb15-78"><a href="#cb15-78" aria-hidden="true" tabindex="-1"></a>                    true_classes.append(labels)</span>
<span id="cb15-79"><a href="#cb15-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-80"><a href="#cb15-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-81"><a href="#cb15-81" aria-hidden="true" tabindex="-1"></a>                    accuracy <span class="op">=</span> accuracy_score(predicted.cpu().numpy(), labels.cpu().numpy())</span>
<span id="cb15-82"><a href="#cb15-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-83"><a href="#cb15-83" aria-hidden="true" tabindex="-1"></a>                    pbar.set_description(<span class="ss">f&#39;Loss: </span><span class="sc">{</span>loss<span class="sc">.</span>item()<span class="sc">:.4f}</span><span class="ss">; Accuracy: </span><span class="sc">{</span>accuracy<span class="sc">:.4f}</span><span class="ss">&#39;</span>)</span>
<span id="cb15-84"><a href="#cb15-84" aria-hidden="true" tabindex="-1"></a>                    pbar.update()</span>
<span id="cb15-85"><a href="#cb15-85" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-86"><a href="#cb15-86" aria-hidden="true" tabindex="-1"></a>        predicted_classes <span class="op">=</span> torch.cat(predicted_classes).detach().to(<span class="st">&#39;cpu&#39;</span>).numpy()</span>
<span id="cb15-87"><a href="#cb15-87" aria-hidden="true" tabindex="-1"></a>        true_classes <span class="op">=</span> torch.cat(true_classes).detach().to(<span class="st">&#39;cpu&#39;</span>).numpy()</span>
<span id="cb15-88"><a href="#cb15-88" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> losses, predicted_classes, true_classes</span>
<span id="cb15-89"><a href="#cb15-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-90"><a href="#cb15-90" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> train(<span class="va">self</span>):</span>
<span id="cb15-91"><a href="#cb15-91" aria-hidden="true" tabindex="-1"></a>        early_stopping <span class="op">=</span> CustomEarlyStopping(patience<span class="op">=</span><span class="dv">4</span>, min_delta<span class="op">=</span><span class="fl">0.005</span>, path<span class="op">=</span><span class="va">self</span>.path, path_model<span class="op">=</span><span class="va">self</span>.path_model)</span>
<span id="cb15-92"><a href="#cb15-92" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.num_epochs):</span>
<span id="cb15-93"><a href="#cb15-93" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">&#39;Epoch:&#39;</span>, epoch)</span>
<span id="cb15-94"><a href="#cb15-94" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.train_one_epoch()</span>
<span id="cb15-95"><a href="#cb15-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-96"><a href="#cb15-96" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">&#39;Validation&#39;</span>)</span>
<span id="cb15-97"><a href="#cb15-97" aria-hidden="true" tabindex="-1"></a>            losses, predicted_classes, true_classes <span class="op">=</span> <span class="va">self</span>.validate()</span>
<span id="cb15-98"><a href="#cb15-98" aria-hidden="true" tabindex="-1"></a>            test_accuracy <span class="op">=</span> accuracy_score(true_classes, predicted_classes)</span>
<span id="cb15-99"><a href="#cb15-99" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-100"><a href="#cb15-100" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.losses[<span class="st">&#39;test&#39;</span>].append(np.mean(losses))</span>
<span id="cb15-101"><a href="#cb15-101" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.accuracies[<span class="st">&#39;test&#39;</span>].append(test_accuracy)</span>
<span id="cb15-102"><a href="#cb15-102" aria-hidden="true" tabindex="-1"></a>            clear_output(wait<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-103"><a href="#cb15-103" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="ss">f&#39;Accuracy: </span><span class="sc">{</span>test_accuracy<span class="sc">:.4f}</span><span class="ss">&#39;</span>)</span>
<span id="cb15-104"><a href="#cb15-104" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>()</span>
<span id="cb15-105"><a href="#cb15-105" aria-hidden="true" tabindex="-1"></a>            <span class="va">self</span>.plot_training_history()</span>
<span id="cb15-106"><a href="#cb15-106" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-107"><a href="#cb15-107" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> <span class="va">self</span>.scheduler:</span>
<span id="cb15-108"><a href="#cb15-108" aria-hidden="true" tabindex="-1"></a>                <span class="va">self</span>.scheduler.step()</span>
<span id="cb15-109"><a href="#cb15-109" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-110"><a href="#cb15-110" aria-hidden="true" tabindex="-1"></a>            early_stopping(test_accuracy, <span class="va">self</span>.model, <span class="va">self</span>.optimizer)</span>
<span id="cb15-111"><a href="#cb15-111" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> early_stopping.early_stop:</span>
<span id="cb15-112"><a href="#cb15-112" aria-hidden="true" tabindex="-1"></a>                <span class="bu">print</span>(<span class="st">&#39;Early Stopping!!!&#39;</span>)</span>
<span id="cb15-113"><a href="#cb15-113" aria-hidden="true" tabindex="-1"></a>                <span class="cf">break</span></span>
<span id="cb15-114"><a href="#cb15-114" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-115"><a href="#cb15-115" aria-hidden="true" tabindex="-1"></a>        clear_output(wait<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb15-116"><a href="#cb15-116" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Обучение завершено!!!&quot;</span>)</span>
<span id="cb15-117"><a href="#cb15-117" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="ss">f&quot;Best accuracy: </span><span class="sc">{</span><span class="va">self</span><span class="sc">.</span>get_best_accuracy()<span class="sc">}</span><span class="ss">&quot;</span>)</span>
<span id="cb15-118"><a href="#cb15-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-119"><a href="#cb15-119" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> plot_training_history(<span class="va">self</span>):</span>
<span id="cb15-120"><a href="#cb15-120" aria-hidden="true" tabindex="-1"></a>        len_data <span class="op">=</span> <span class="bu">len</span>(<span class="va">self</span>.losses[<span class="st">&#39;train&#39;</span>])</span>
<span id="cb15-121"><a href="#cb15-121" aria-hidden="true" tabindex="-1"></a>        plt.figure(figsize<span class="op">=</span>(<span class="dv">12</span>, <span class="dv">4</span>))</span>
<span id="cb15-122"><a href="#cb15-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-123"><a href="#cb15-123" aria-hidden="true" tabindex="-1"></a>        <span class="co"># График функции потерь</span></span>
<span id="cb15-124"><a href="#cb15-124" aria-hidden="true" tabindex="-1"></a>        plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)</span>
<span id="cb15-125"><a href="#cb15-125" aria-hidden="true" tabindex="-1"></a>        plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, len_data <span class="op">+</span> <span class="dv">1</span>), <span class="va">self</span>.losses[<span class="st">&#39;train&#39;</span>], marker<span class="op">=</span><span class="st">&#39;o&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Loss&#39;</span>)</span>
<span id="cb15-126"><a href="#cb15-126" aria-hidden="true" tabindex="-1"></a>        plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, len_data <span class="op">+</span> <span class="dv">1</span>), <span class="va">self</span>.losses[<span class="st">&#39;test&#39;</span>], marker<span class="op">=</span><span class="st">&#39;o&#39;</span>, label<span class="op">=</span><span class="st">&#39;Test Loss&#39;</span>)</span>
<span id="cb15-127"><a href="#cb15-127" aria-hidden="true" tabindex="-1"></a>        plt.xlabel(<span class="st">&#39;Epoch&#39;</span>)</span>
<span id="cb15-128"><a href="#cb15-128" aria-hidden="true" tabindex="-1"></a>        plt.ylabel(<span class="st">&#39;Loss&#39;</span>)</span>
<span id="cb15-129"><a href="#cb15-129" aria-hidden="true" tabindex="-1"></a>        plt.legend()</span>
<span id="cb15-130"><a href="#cb15-130" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="st">&#39;Training and Test Loss&#39;</span>)</span>
<span id="cb15-131"><a href="#cb15-131" aria-hidden="true" tabindex="-1"></a>        plt.grid(<span class="va">True</span>)</span>
<span id="cb15-132"><a href="#cb15-132" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-133"><a href="#cb15-133" aria-hidden="true" tabindex="-1"></a>        <span class="co"># График точности</span></span>
<span id="cb15-134"><a href="#cb15-134" aria-hidden="true" tabindex="-1"></a>        plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>)</span>
<span id="cb15-135"><a href="#cb15-135" aria-hidden="true" tabindex="-1"></a>        plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, len_data <span class="op">+</span> <span class="dv">1</span>), <span class="va">self</span>.accuracies[<span class="st">&#39;train&#39;</span>], marker<span class="op">=</span><span class="st">&#39;o&#39;</span>, label<span class="op">=</span><span class="st">&#39;Training Accuracy&#39;</span>)</span>
<span id="cb15-136"><a href="#cb15-136" aria-hidden="true" tabindex="-1"></a>        plt.plot(<span class="bu">range</span>(<span class="dv">1</span>, len_data <span class="op">+</span> <span class="dv">1</span>), <span class="va">self</span>.accuracies[<span class="st">&#39;test&#39;</span>], marker<span class="op">=</span><span class="st">&#39;o&#39;</span>, label<span class="op">=</span><span class="st">&#39;Test Accuracy&#39;</span>)</span>
<span id="cb15-137"><a href="#cb15-137" aria-hidden="true" tabindex="-1"></a>        plt.xlabel(<span class="st">&#39;Epoch&#39;</span>)</span>
<span id="cb15-138"><a href="#cb15-138" aria-hidden="true" tabindex="-1"></a>        plt.ylabel(<span class="st">&#39;Accuracy&#39;</span>)</span>
<span id="cb15-139"><a href="#cb15-139" aria-hidden="true" tabindex="-1"></a>        plt.legend()</span>
<span id="cb15-140"><a href="#cb15-140" aria-hidden="true" tabindex="-1"></a>        plt.title(<span class="st">&#39;Training and Test Accuracy&#39;</span>)</span>
<span id="cb15-141"><a href="#cb15-141" aria-hidden="true" tabindex="-1"></a>        plt.grid(<span class="va">True</span>)</span>
<span id="cb15-142"><a href="#cb15-142" aria-hidden="true" tabindex="-1"></a>        plt.tight_layout()</span>
<span id="cb15-143"><a href="#cb15-143" aria-hidden="true" tabindex="-1"></a>        plt.show()</span>
<span id="cb15-144"><a href="#cb15-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-145"><a href="#cb15-145" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> get_best_accuracy(<span class="va">self</span>):</span>
<span id="cb15-146"><a href="#cb15-146" aria-hidden="true" tabindex="-1"></a>        checkpoint <span class="op">=</span> torch.load(<span class="va">self</span>.path)</span>
<span id="cb15-147"><a href="#cb15-147" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> checkpoint[<span class="st">&#39;best_accuracy&#39;</span>]</span></code></pre></div>
</div>
<div class="cell markdown" id="d681bc31">
<p>В данной работе проведем transfer learning для AlexNet, ResNet34, MobileNet V2, EfficientNetV2. Так как данные модели обучались ранее на imagenet с размером 224x224, то и нам предется сделать Resize изображений. В качестве оптимизатора, попробуем обучить модели с помощью нового оптимизатора lion и старого доброго adam (<a href="https://github.com/lucidrains/lion-pytorch" class="uri">https://github.com/lucidrains/lion-pytorch</a>). Обучим два типа моделей: с freeze слоев и полным fine tuning.</p>
</div>
<section id="alexnet" class="cell markdown" id="a8542901">
<h3>AlexNet</h3>
<h4 id="freeze-layers">freeze layers</h4>
</section>
<div class="cell code" id="c69c4ed2">
<div class="sourceCode" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AlexNetFreeze(nn.Module):</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_classes):</span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(AlexNetFreeze, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.alexnet <span class="op">=</span> models.alexnet( weights<span class="op">=</span><span class="st">&#39;DEFAULT&#39;</span>)</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> param <span class="kw">in</span> <span class="va">self</span>.alexnet.parameters(): param.requires_grad <span class="op">=</span> <span class="va">False</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.alexnet.classifier[<span class="dv">6</span>] <span class="op">=</span> torch.nn.Linear(</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>            in_features<span class="op">=</span><span class="va">self</span>.alexnet.classifier[<span class="dv">6</span>].in_features,</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>            out_features<span class="op">=</span>num_classes)</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.alexnet(x)</span></code></pre></div>
</div>
<div class="cell code" id="470b3a38" data-outputId="a85d087a-0b98-4f9b-c99a-45bb6ef21352">
<div class="sourceCode" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>input_size <span class="op">=</span> (<span class="dv">3</span>, <span class="dv">224</span>, <span class="dv">224</span>)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">&quot;cuda&quot;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span>)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>alexnet <span class="op">=</span> AlexNetFreeze(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>alexnet <span class="op">=</span> alexnet.to(device)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>summary(alexnet, input_size<span class="op">=</span>input_size)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 64, 55, 55]          23,296
              ReLU-2           [-1, 64, 55, 55]               0
         MaxPool2d-3           [-1, 64, 27, 27]               0
            Conv2d-4          [-1, 192, 27, 27]         307,392
              ReLU-5          [-1, 192, 27, 27]               0
         MaxPool2d-6          [-1, 192, 13, 13]               0
            Conv2d-7          [-1, 384, 13, 13]         663,936
              ReLU-8          [-1, 384, 13, 13]               0
            Conv2d-9          [-1, 256, 13, 13]         884,992
             ReLU-10          [-1, 256, 13, 13]               0
           Conv2d-11          [-1, 256, 13, 13]         590,080
             ReLU-12          [-1, 256, 13, 13]               0
        MaxPool2d-13            [-1, 256, 6, 6]               0
AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0
          Dropout-15                 [-1, 9216]               0
           Linear-16                 [-1, 4096]      37,752,832
             ReLU-17                 [-1, 4096]               0
          Dropout-18                 [-1, 4096]               0
           Linear-19                 [-1, 4096]      16,781,312
             ReLU-20                 [-1, 4096]               0
           Linear-21                   [-1, 10]          40,970
          AlexNet-22                   [-1, 10]               0
================================================================
Total params: 57,044,810
Trainable params: 40,970
Non-trainable params: 57,003,840
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 8.37
Params size (MB): 217.61
Estimated Total Size (MB): 226.55
----------------------------------------------------------------
</code></pre>
</div>
</div>
<div class="cell markdown" id="1fd5498b">
<p>По итогу имеем <strong>40 970</strong> обучаемых параметров</p>
</div>
<div class="cell code" id="c563a240" data-outputId="c938c460-b6f2-416c-e0f3-205768805ac5">
<div class="sourceCode" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a>freeze_alexnet_lion <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>alexnet,</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;Lion&#39;</span>,</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">256</span>,</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>freeze_alexnet_lion.train()</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>freeze_alexnet_lion.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Обучение завершено!!!
Best accuracy: 0.8021
</code></pre>
</div>
<div class="output display_data">
<p><img src="372ccc761894f3023af8e71ff086f22ddb53e6f1.png" /></p>
</div>
</div>
<div class="cell markdown" id="13b9f57d">
<p>Теперь обучим используя AdamW</p>
</div>
<div class="cell code" id="17d4e171" data-outputId="2ff9f1c3-19b1-416c-a18d-851144507216">
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>alexnet <span class="op">=</span> AlexNetFreeze(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>freeze_alexnet_adamw <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>alexnet,</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;AdamW&#39;</span>,</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">256</span>,</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb21-12"><a href="#cb21-12" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb21-13"><a href="#cb21-13" aria-hidden="true" tabindex="-1"></a>freeze_alexnet_adamw.train()</span>
<span id="cb21-14"><a href="#cb21-14" aria-hidden="true" tabindex="-1"></a>freeze_alexnet_adamw.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Обучение завершено!!!
Best accuracy: 0.7865
</code></pre>
</div>
<div class="output display_data">
<p><img src="c7364c5bc852f1691741ffc8dd17a4e96cfa4afc.png" /></p>
</div>
</div>
<div class="cell markdown" id="db584e79">
<p>На первый взгляд можно сказать, что для Lion необходимо гораздо меньше эпох для полного обучения (12 эпох против 18 у AdamW), также хочется сказать, что время, затраченное на одну эпоху у Lion меньше, чем у AdamW</p>
</div>
<section id="finetuning" class="cell markdown" id="afe44d5a">
<h4>finetuning</h4>
</section>
<div class="cell code" id="5ecb5d9f">
<div class="sourceCode" id="cb23"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> AlexNet(nn.Module):</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_classes):</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(AlexNet, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.alexnet <span class="op">=</span> models.alexnet( weights<span class="op">=</span><span class="st">&#39;DEFAULT&#39;</span>)</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.alexnet.classifier[<span class="dv">6</span>] <span class="op">=</span> torch.nn.Linear(</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>            in_features<span class="op">=</span><span class="va">self</span>.alexnet.classifier[<span class="dv">6</span>].in_features,</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>            out_features<span class="op">=</span>num_classes)</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.alexnet(x)</span></code></pre></div>
</div>
<div class="cell code" id="3370103f" data-outputId="54834b89-671b-4cc3-b9e7-c744fb8608ec">
<div class="sourceCode" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>input_size <span class="op">=</span> (<span class="dv">3</span>, <span class="dv">224</span>, <span class="dv">224</span>)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">&quot;cuda&quot;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span>)</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>alexnet <span class="op">=</span> AlexNet(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>alexnet <span class="op">=</span> alexnet.to(device)</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>summary(alexnet, input_size<span class="op">=</span>input_size)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 64, 55, 55]          23,296
              ReLU-2           [-1, 64, 55, 55]               0
         MaxPool2d-3           [-1, 64, 27, 27]               0
            Conv2d-4          [-1, 192, 27, 27]         307,392
              ReLU-5          [-1, 192, 27, 27]               0
         MaxPool2d-6          [-1, 192, 13, 13]               0
            Conv2d-7          [-1, 384, 13, 13]         663,936
              ReLU-8          [-1, 384, 13, 13]               0
            Conv2d-9          [-1, 256, 13, 13]         884,992
             ReLU-10          [-1, 256, 13, 13]               0
           Conv2d-11          [-1, 256, 13, 13]         590,080
             ReLU-12          [-1, 256, 13, 13]               0
        MaxPool2d-13            [-1, 256, 6, 6]               0
AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0
          Dropout-15                 [-1, 9216]               0
           Linear-16                 [-1, 4096]      37,752,832
             ReLU-17                 [-1, 4096]               0
          Dropout-18                 [-1, 4096]               0
           Linear-19                 [-1, 4096]      16,781,312
             ReLU-20                 [-1, 4096]               0
           Linear-21                   [-1, 10]          40,970
          AlexNet-22                   [-1, 10]               0
================================================================
Total params: 57,044,810
Trainable params: 57,044,810
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 8.37
Params size (MB): 217.61
Estimated Total Size (MB): 226.55
----------------------------------------------------------------
</code></pre>
</div>
</div>
<div class="cell code" id="35c6e5e5" data-outputId="9812c10a-9c2b-4900-d73b-ba4375bc3df7">
<div class="sourceCode" id="cb26"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>trainer_alexnet_lion <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>alexnet,</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;Lion&#39;</span>,</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>trainer_alexnet_lion.train()</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>trainer_alexnet_lion.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Обучение завершено!!!
Best accuracy: 0.9056
</code></pre>
</div>
<div class="output display_data">
<p><img src="6f6c51ad2f966fce065d84906ce9c5e31215e681.png" /></p>
</div>
</div>
<div class="cell markdown" id="704bb3f9">
<p>Отлично, при fine tuning всех слоев показал гораздо лучше результат, прирост почти на 10%</p>
</div>
<div class="cell code" id="8585095e" data-outputId="76445da2-b69c-494b-c718-c01fa990bb1e">
<div class="sourceCode" id="cb28"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>alexnet <span class="op">=</span> AlexNet(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>trainer_alexnet_adamw <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>alexnet,</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;AdamW&#39;</span>,</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a>trainer_alexnet_adamw.train()</span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a>trainer_alexnet_adamw.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Обучение завершено!!!
Best accuracy: 0.9244
</code></pre>
</div>
<div class="output display_data">
<p><img src="942f63315ff58c72ebdb284ac66dbf74c3fdb4d6.png" /></p>
</div>
</div>
<div class="cell markdown" id="db742166">
<p>Как видим, что при finetuning AdamW лучше сошелся, чем Lion. Была обучена модель 2012 года, теперь обучим модель 2015 года</p>
</div>
<section id="resnet-34" class="cell markdown" id="27cc72e0">
<h3>ResNet 34</h3>
</section>
<div class="cell code" id="809f1f94">
<div class="sourceCode" id="cb30"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ResNetFreeze(nn.Module):</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_classes):</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(ResNetFreeze, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.resnet34 <span class="op">=</span> models.resnet34( weights<span class="op">=</span><span class="st">&#39;DEFAULT&#39;</span>)</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> param <span class="kw">in</span> <span class="va">self</span>.resnet34.parameters(): param.requires_grad <span class="op">=</span> <span class="va">False</span></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.resnet34.fc <span class="op">=</span> torch.nn.Linear(</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>            in_features<span class="op">=</span><span class="va">self</span>.resnet34.fc.in_features,</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>            out_features<span class="op">=</span>num_classes)</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.resnet34(x)</span></code></pre></div>
</div>
<div class="cell code" id="4961e918" data-outputId="b19241f1-3712-47c1-ead9-0ea24f6e7e04">
<div class="sourceCode" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>resnet34 <span class="op">=</span> ResNetFreeze(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a>resnet34 <span class="op">=</span> resnet34.to(device)</span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>summary(resnet34, input_size<span class="op">=</span>input_size)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 112, 112]           9,408
       BatchNorm2d-2         [-1, 64, 112, 112]             128
              ReLU-3         [-1, 64, 112, 112]               0
         MaxPool2d-4           [-1, 64, 56, 56]               0
            Conv2d-5           [-1, 64, 56, 56]          36,864
       BatchNorm2d-6           [-1, 64, 56, 56]             128
              ReLU-7           [-1, 64, 56, 56]               0
            Conv2d-8           [-1, 64, 56, 56]          36,864
       BatchNorm2d-9           [-1, 64, 56, 56]             128
             ReLU-10           [-1, 64, 56, 56]               0
       BasicBlock-11           [-1, 64, 56, 56]               0
           Conv2d-12           [-1, 64, 56, 56]          36,864
      BatchNorm2d-13           [-1, 64, 56, 56]             128
             ReLU-14           [-1, 64, 56, 56]               0
           Conv2d-15           [-1, 64, 56, 56]          36,864
      BatchNorm2d-16           [-1, 64, 56, 56]             128
             ReLU-17           [-1, 64, 56, 56]               0
       BasicBlock-18           [-1, 64, 56, 56]               0
           Conv2d-19           [-1, 64, 56, 56]          36,864
      BatchNorm2d-20           [-1, 64, 56, 56]             128
             ReLU-21           [-1, 64, 56, 56]               0
           Conv2d-22           [-1, 64, 56, 56]          36,864
      BatchNorm2d-23           [-1, 64, 56, 56]             128
             ReLU-24           [-1, 64, 56, 56]               0
       BasicBlock-25           [-1, 64, 56, 56]               0
           Conv2d-26          [-1, 128, 28, 28]          73,728
      BatchNorm2d-27          [-1, 128, 28, 28]             256
             ReLU-28          [-1, 128, 28, 28]               0
           Conv2d-29          [-1, 128, 28, 28]         147,456
      BatchNorm2d-30          [-1, 128, 28, 28]             256
           Conv2d-31          [-1, 128, 28, 28]           8,192
      BatchNorm2d-32          [-1, 128, 28, 28]             256
             ReLU-33          [-1, 128, 28, 28]               0
       BasicBlock-34          [-1, 128, 28, 28]               0
           Conv2d-35          [-1, 128, 28, 28]         147,456
      BatchNorm2d-36          [-1, 128, 28, 28]             256
             ReLU-37          [-1, 128, 28, 28]               0
           Conv2d-38          [-1, 128, 28, 28]         147,456
      BatchNorm2d-39          [-1, 128, 28, 28]             256
             ReLU-40          [-1, 128, 28, 28]               0
       BasicBlock-41          [-1, 128, 28, 28]               0
           Conv2d-42          [-1, 128, 28, 28]         147,456
      BatchNorm2d-43          [-1, 128, 28, 28]             256
             ReLU-44          [-1, 128, 28, 28]               0
           Conv2d-45          [-1, 128, 28, 28]         147,456
      BatchNorm2d-46          [-1, 128, 28, 28]             256
             ReLU-47          [-1, 128, 28, 28]               0
       BasicBlock-48          [-1, 128, 28, 28]               0
           Conv2d-49          [-1, 128, 28, 28]         147,456
      BatchNorm2d-50          [-1, 128, 28, 28]             256
             ReLU-51          [-1, 128, 28, 28]               0
           Conv2d-52          [-1, 128, 28, 28]         147,456
      BatchNorm2d-53          [-1, 128, 28, 28]             256
             ReLU-54          [-1, 128, 28, 28]               0
       BasicBlock-55          [-1, 128, 28, 28]               0
           Conv2d-56          [-1, 256, 14, 14]         294,912
      BatchNorm2d-57          [-1, 256, 14, 14]             512
             ReLU-58          [-1, 256, 14, 14]               0
           Conv2d-59          [-1, 256, 14, 14]         589,824
      BatchNorm2d-60          [-1, 256, 14, 14]             512
           Conv2d-61          [-1, 256, 14, 14]          32,768
      BatchNorm2d-62          [-1, 256, 14, 14]             512
             ReLU-63          [-1, 256, 14, 14]               0
       BasicBlock-64          [-1, 256, 14, 14]               0
           Conv2d-65          [-1, 256, 14, 14]         589,824
      BatchNorm2d-66          [-1, 256, 14, 14]             512
             ReLU-67          [-1, 256, 14, 14]               0
           Conv2d-68          [-1, 256, 14, 14]         589,824
      BatchNorm2d-69          [-1, 256, 14, 14]             512
             ReLU-70          [-1, 256, 14, 14]               0
       BasicBlock-71          [-1, 256, 14, 14]               0
           Conv2d-72          [-1, 256, 14, 14]         589,824
      BatchNorm2d-73          [-1, 256, 14, 14]             512
             ReLU-74          [-1, 256, 14, 14]               0
           Conv2d-75          [-1, 256, 14, 14]         589,824
      BatchNorm2d-76          [-1, 256, 14, 14]             512
             ReLU-77          [-1, 256, 14, 14]               0
       BasicBlock-78          [-1, 256, 14, 14]               0
           Conv2d-79          [-1, 256, 14, 14]         589,824
      BatchNorm2d-80          [-1, 256, 14, 14]             512
             ReLU-81          [-1, 256, 14, 14]               0
           Conv2d-82          [-1, 256, 14, 14]         589,824
      BatchNorm2d-83          [-1, 256, 14, 14]             512
             ReLU-84          [-1, 256, 14, 14]               0
       BasicBlock-85          [-1, 256, 14, 14]               0
           Conv2d-86          [-1, 256, 14, 14]         589,824
      BatchNorm2d-87          [-1, 256, 14, 14]             512
             ReLU-88          [-1, 256, 14, 14]               0
           Conv2d-89          [-1, 256, 14, 14]         589,824
      BatchNorm2d-90          [-1, 256, 14, 14]             512
             ReLU-91          [-1, 256, 14, 14]               0
       BasicBlock-92          [-1, 256, 14, 14]               0
           Conv2d-93          [-1, 256, 14, 14]         589,824
      BatchNorm2d-94          [-1, 256, 14, 14]             512
             ReLU-95          [-1, 256, 14, 14]               0
           Conv2d-96          [-1, 256, 14, 14]         589,824
      BatchNorm2d-97          [-1, 256, 14, 14]             512
             ReLU-98          [-1, 256, 14, 14]               0
       BasicBlock-99          [-1, 256, 14, 14]               0
          Conv2d-100            [-1, 512, 7, 7]       1,179,648
     BatchNorm2d-101            [-1, 512, 7, 7]           1,024
            ReLU-102            [-1, 512, 7, 7]               0
          Conv2d-103            [-1, 512, 7, 7]       2,359,296
     BatchNorm2d-104            [-1, 512, 7, 7]           1,024
          Conv2d-105            [-1, 512, 7, 7]         131,072
     BatchNorm2d-106            [-1, 512, 7, 7]           1,024
            ReLU-107            [-1, 512, 7, 7]               0
      BasicBlock-108            [-1, 512, 7, 7]               0
          Conv2d-109            [-1, 512, 7, 7]       2,359,296
     BatchNorm2d-110            [-1, 512, 7, 7]           1,024
            ReLU-111            [-1, 512, 7, 7]               0
          Conv2d-112            [-1, 512, 7, 7]       2,359,296
     BatchNorm2d-113            [-1, 512, 7, 7]           1,024
            ReLU-114            [-1, 512, 7, 7]               0
      BasicBlock-115            [-1, 512, 7, 7]               0
          Conv2d-116            [-1, 512, 7, 7]       2,359,296
     BatchNorm2d-117            [-1, 512, 7, 7]           1,024
            ReLU-118            [-1, 512, 7, 7]               0
          Conv2d-119            [-1, 512, 7, 7]       2,359,296
     BatchNorm2d-120            [-1, 512, 7, 7]           1,024
            ReLU-121            [-1, 512, 7, 7]               0
      BasicBlock-122            [-1, 512, 7, 7]               0
AdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0
          Linear-124                   [-1, 10]           5,130
          ResNet-125                   [-1, 10]               0
================================================================
Total params: 21,289,802
Trainable params: 5,130
Non-trainable params: 21,284,672
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 96.28
Params size (MB): 81.21
Estimated Total Size (MB): 178.07
----------------------------------------------------------------
</code></pre>
</div>
</div>
<div class="cell code" id="c688aa1a" data-outputId="a4ef2ff8-ba45-4884-bae6-e0c8b6c4f4fc">
<div class="sourceCode" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>freeze_resnet34_lion <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>resnet34,</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;Lion&#39;</span>,</span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>freeze_resnet34_lion.train()</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>freeze_resnet34_lion.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Обучение завершено!!!
Best accuracy: 0.8284
</code></pre>
</div>
<div class="output display_data">
<p><img src="8ea2846695c1823aca0907cffc5074ab77ec5d79.png" /></p>
</div>
</div>
<div class="cell code" id="83dc4648">
<div class="sourceCode" id="cb35"><pre class="sourceCode python"><code class="sourceCode python"></code></pre></div>
</div>
<div class="cell code" id="120f5b99" data-outputId="9fefca45-fc42-49a3-ab11-6102fbde8acb">
<div class="sourceCode" id="cb36"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>resnet34 <span class="op">=</span> ResNetFreeze(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a>freeze_resnet34_adamw <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>resnet34,</span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;AdamW&#39;</span>,</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>freeze_resnet34_adamw.train()</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>freeze_resnet34_adamw.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Обучение завершено!!!
Best accuracy: 0.815
</code></pre>
</div>
<div class="output display_data">
<p><img src="50ea5dc7c5d73bd93bbf71fabcf6b95f7ddf764b.png" /></p>
</div>
</div>
<div class="cell markdown" id="9d6ac8f9">
<p>Тенденция сохраняется, для freeze Lion обучает модели быстрее и лучше сходится</p>
</div>
<section id="finetuning" class="cell markdown" id="dbfb786b">
<h4>finetuning</h4>
</section>
<div class="cell code" id="&quot;11898594&quot;">
<div class="sourceCode" id="cb38"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ResNet(nn.Module):</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_classes):</span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(ResNet, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.resnet34 <span class="op">=</span> models.resnet34( weights<span class="op">=</span><span class="st">&#39;DEFAULT&#39;</span>)</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.resnet34.fc <span class="op">=</span> torch.nn.Linear(</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>            in_features<span class="op">=</span><span class="va">self</span>.resnet34.fc.in_features,</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>            out_features<span class="op">=</span>num_classes)</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.resnet34(x)</span></code></pre></div>
</div>
<div class="cell code" id="d36dd991" data-outputId="024fcd78-bda1-410b-dcfd-023384392d4e">
<div class="sourceCode" id="cb39"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a>resnet34 <span class="op">=</span> ResNet(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>resnet34 <span class="op">=</span> resnet34.to(device)</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>summary(resnet34, input_size<span class="op">=</span>input_size)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 112, 112]           9,408
       BatchNorm2d-2         [-1, 64, 112, 112]             128
              ReLU-3         [-1, 64, 112, 112]               0
         MaxPool2d-4           [-1, 64, 56, 56]               0
            Conv2d-5           [-1, 64, 56, 56]          36,864
       BatchNorm2d-6           [-1, 64, 56, 56]             128
              ReLU-7           [-1, 64, 56, 56]               0
            Conv2d-8           [-1, 64, 56, 56]          36,864
       BatchNorm2d-9           [-1, 64, 56, 56]             128
             ReLU-10           [-1, 64, 56, 56]               0
       BasicBlock-11           [-1, 64, 56, 56]               0
           Conv2d-12           [-1, 64, 56, 56]          36,864
      BatchNorm2d-13           [-1, 64, 56, 56]             128
             ReLU-14           [-1, 64, 56, 56]               0
           Conv2d-15           [-1, 64, 56, 56]          36,864
      BatchNorm2d-16           [-1, 64, 56, 56]             128
             ReLU-17           [-1, 64, 56, 56]               0
       BasicBlock-18           [-1, 64, 56, 56]               0
           Conv2d-19           [-1, 64, 56, 56]          36,864
      BatchNorm2d-20           [-1, 64, 56, 56]             128
             ReLU-21           [-1, 64, 56, 56]               0
           Conv2d-22           [-1, 64, 56, 56]          36,864
      BatchNorm2d-23           [-1, 64, 56, 56]             128
             ReLU-24           [-1, 64, 56, 56]               0
       BasicBlock-25           [-1, 64, 56, 56]               0
           Conv2d-26          [-1, 128, 28, 28]          73,728
      BatchNorm2d-27          [-1, 128, 28, 28]             256
             ReLU-28          [-1, 128, 28, 28]               0
           Conv2d-29          [-1, 128, 28, 28]         147,456
      BatchNorm2d-30          [-1, 128, 28, 28]             256
           Conv2d-31          [-1, 128, 28, 28]           8,192
      BatchNorm2d-32          [-1, 128, 28, 28]             256
             ReLU-33          [-1, 128, 28, 28]               0
       BasicBlock-34          [-1, 128, 28, 28]               0
           Conv2d-35          [-1, 128, 28, 28]         147,456
      BatchNorm2d-36          [-1, 128, 28, 28]             256
             ReLU-37          [-1, 128, 28, 28]               0
           Conv2d-38          [-1, 128, 28, 28]         147,456
      BatchNorm2d-39          [-1, 128, 28, 28]             256
             ReLU-40          [-1, 128, 28, 28]               0
       BasicBlock-41          [-1, 128, 28, 28]               0
           Conv2d-42          [-1, 128, 28, 28]         147,456
      BatchNorm2d-43          [-1, 128, 28, 28]             256
             ReLU-44          [-1, 128, 28, 28]               0
           Conv2d-45          [-1, 128, 28, 28]         147,456
      BatchNorm2d-46          [-1, 128, 28, 28]             256
             ReLU-47          [-1, 128, 28, 28]               0
       BasicBlock-48          [-1, 128, 28, 28]               0
           Conv2d-49          [-1, 128, 28, 28]         147,456
      BatchNorm2d-50          [-1, 128, 28, 28]             256
             ReLU-51          [-1, 128, 28, 28]               0
           Conv2d-52          [-1, 128, 28, 28]         147,456
      BatchNorm2d-53          [-1, 128, 28, 28]             256
             ReLU-54          [-1, 128, 28, 28]               0
       BasicBlock-55          [-1, 128, 28, 28]               0
           Conv2d-56          [-1, 256, 14, 14]         294,912
      BatchNorm2d-57          [-1, 256, 14, 14]             512
             ReLU-58          [-1, 256, 14, 14]               0
           Conv2d-59          [-1, 256, 14, 14]         589,824
      BatchNorm2d-60          [-1, 256, 14, 14]             512
           Conv2d-61          [-1, 256, 14, 14]          32,768
      BatchNorm2d-62          [-1, 256, 14, 14]             512
             ReLU-63          [-1, 256, 14, 14]               0
       BasicBlock-64          [-1, 256, 14, 14]               0
           Conv2d-65          [-1, 256, 14, 14]         589,824
      BatchNorm2d-66          [-1, 256, 14, 14]             512
             ReLU-67          [-1, 256, 14, 14]               0
           Conv2d-68          [-1, 256, 14, 14]         589,824
      BatchNorm2d-69          [-1, 256, 14, 14]             512
             ReLU-70          [-1, 256, 14, 14]               0
       BasicBlock-71          [-1, 256, 14, 14]               0
           Conv2d-72          [-1, 256, 14, 14]         589,824
      BatchNorm2d-73          [-1, 256, 14, 14]             512
             ReLU-74          [-1, 256, 14, 14]               0
           Conv2d-75          [-1, 256, 14, 14]         589,824
      BatchNorm2d-76          [-1, 256, 14, 14]             512
             ReLU-77          [-1, 256, 14, 14]               0
       BasicBlock-78          [-1, 256, 14, 14]               0
           Conv2d-79          [-1, 256, 14, 14]         589,824
      BatchNorm2d-80          [-1, 256, 14, 14]             512
             ReLU-81          [-1, 256, 14, 14]               0
           Conv2d-82          [-1, 256, 14, 14]         589,824
      BatchNorm2d-83          [-1, 256, 14, 14]             512
             ReLU-84          [-1, 256, 14, 14]               0
       BasicBlock-85          [-1, 256, 14, 14]               0
           Conv2d-86          [-1, 256, 14, 14]         589,824
      BatchNorm2d-87          [-1, 256, 14, 14]             512
             ReLU-88          [-1, 256, 14, 14]               0
           Conv2d-89          [-1, 256, 14, 14]         589,824
      BatchNorm2d-90          [-1, 256, 14, 14]             512
             ReLU-91          [-1, 256, 14, 14]               0
       BasicBlock-92          [-1, 256, 14, 14]               0
           Conv2d-93          [-1, 256, 14, 14]         589,824
      BatchNorm2d-94          [-1, 256, 14, 14]             512
             ReLU-95          [-1, 256, 14, 14]               0
           Conv2d-96          [-1, 256, 14, 14]         589,824
      BatchNorm2d-97          [-1, 256, 14, 14]             512
             ReLU-98          [-1, 256, 14, 14]               0
       BasicBlock-99          [-1, 256, 14, 14]               0
          Conv2d-100            [-1, 512, 7, 7]       1,179,648
     BatchNorm2d-101            [-1, 512, 7, 7]           1,024
            ReLU-102            [-1, 512, 7, 7]               0
          Conv2d-103            [-1, 512, 7, 7]       2,359,296
     BatchNorm2d-104            [-1, 512, 7, 7]           1,024
          Conv2d-105            [-1, 512, 7, 7]         131,072
     BatchNorm2d-106            [-1, 512, 7, 7]           1,024
            ReLU-107            [-1, 512, 7, 7]               0
      BasicBlock-108            [-1, 512, 7, 7]               0
          Conv2d-109            [-1, 512, 7, 7]       2,359,296
     BatchNorm2d-110            [-1, 512, 7, 7]           1,024
            ReLU-111            [-1, 512, 7, 7]               0
          Conv2d-112            [-1, 512, 7, 7]       2,359,296
     BatchNorm2d-113            [-1, 512, 7, 7]           1,024
            ReLU-114            [-1, 512, 7, 7]               0
      BasicBlock-115            [-1, 512, 7, 7]               0
          Conv2d-116            [-1, 512, 7, 7]       2,359,296
     BatchNorm2d-117            [-1, 512, 7, 7]           1,024
            ReLU-118            [-1, 512, 7, 7]               0
          Conv2d-119            [-1, 512, 7, 7]       2,359,296
     BatchNorm2d-120            [-1, 512, 7, 7]           1,024
            ReLU-121            [-1, 512, 7, 7]               0
      BasicBlock-122            [-1, 512, 7, 7]               0
AdaptiveAvgPool2d-123            [-1, 512, 1, 1]               0
          Linear-124                   [-1, 10]           5,130
          ResNet-125                   [-1, 10]               0
================================================================
Total params: 21,289,802
Trainable params: 21,289,802
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 96.28
Params size (MB): 81.21
Estimated Total Size (MB): 178.07
----------------------------------------------------------------
</code></pre>
</div>
</div>
<div class="cell code" id="50a1187f" data-outputId="6ea877a9-2fd2-4392-906f-d287e852b79a">
<div class="sourceCode" id="cb41"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a>trainer_resnet34_lion <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>resnet34,</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;Lion&#39;</span>,</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.7</span>,</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>trainer_resnet34_lion.train()</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>trainer_resnet34_lion.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Обучение завершено!!!
Best accuracy: 0.9552
</code></pre>
</div>
<div class="output display_data">
<p><img src="9ca13975894f45b61ce83477d1be4ee96f3075cc.png" /></p>
</div>
</div>
<div class="cell code" id="81fdfa6b" data-outputId="8c34cca8-7d1b-4991-f146-55a12cf300b9">
<div class="sourceCode" id="cb43"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>resnet34 <span class="op">=</span> ResNet(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>trainer_resnet34_adamw <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>resnet34,</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;AdamW&#39;</span>,</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb43-12"><a href="#cb43-12" aria-hidden="true" tabindex="-1"></a>trainer_resnet34_adamw.train()</span>
<span id="cb43-13"><a href="#cb43-13" aria-hidden="true" tabindex="-1"></a>trainer_resnet34_adamw.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Обучение завершено!!!
Best accuracy: 0.9637
</code></pre>
</div>
<div class="output display_data">
<p><img src="f1f43cbd3e1873dedcc376133ae2b5e447d4da3b.png" /></p>
</div>
</div>
<div class="cell markdown" id="3b53388e">
<p>Отлично! Получили почти похожий результат, но <strong>AdamW</strong> чуть лучше справился с задачей в <strong>96,37%</strong></p>
<p>Теперь посмотрим модель 2018 года</p>
</div>
<section id="mobilenet-v2" class="cell markdown" id="50163bab">
<h3>MobileNet V2</h3>
</section>
<div class="cell code" id="f3b24814">
<div class="sourceCode" id="cb45"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MobileNetFreeze(nn.Module):</span>
<span id="cb45-2"><a href="#cb45-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_classes):</span>
<span id="cb45-3"><a href="#cb45-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(MobileNetFreeze, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb45-4"><a href="#cb45-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mobilenet_v2 <span class="op">=</span> models.mobilenet_v2( weights<span class="op">=</span><span class="st">&#39;DEFAULT&#39;</span>)</span>
<span id="cb45-5"><a href="#cb45-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> param <span class="kw">in</span> <span class="va">self</span>.mobilenet_v2.parameters(): param.requires_grad <span class="op">=</span> <span class="va">False</span></span>
<span id="cb45-6"><a href="#cb45-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-7"><a href="#cb45-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mobilenet_v2.classifier[<span class="dv">1</span>] <span class="op">=</span> torch.nn.Linear(</span>
<span id="cb45-8"><a href="#cb45-8" aria-hidden="true" tabindex="-1"></a>            in_features<span class="op">=</span><span class="va">self</span>.mobilenet_v2.classifier[<span class="dv">1</span>].in_features,</span>
<span id="cb45-9"><a href="#cb45-9" aria-hidden="true" tabindex="-1"></a>            out_features<span class="op">=</span>num_classes)</span>
<span id="cb45-10"><a href="#cb45-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb45-11"><a href="#cb45-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb45-12"><a href="#cb45-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.mobilenet_v2(x)</span></code></pre></div>
</div>
<div class="cell code" id="167d5d70" data-outputId="d032d4cd-8eff-4839-aa3e-57e2ced6ea10">
<div class="sourceCode" id="cb46"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>input_size <span class="op">=</span> (<span class="dv">3</span>, <span class="dv">224</span>, <span class="dv">224</span>)</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">&quot;cuda&quot;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span>)</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>mobilenet_v2 <span class="op">=</span> MobileNetFreeze(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>mobilenet_v2 <span class="op">=</span> mobilenet_v2.to(device)</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>summary(mobilenet_v2, input_size<span class="op">=</span>input_size)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 32, 112, 112]             864
       BatchNorm2d-2         [-1, 32, 112, 112]              64
             ReLU6-3         [-1, 32, 112, 112]               0
            Conv2d-4         [-1, 32, 112, 112]             288
       BatchNorm2d-5         [-1, 32, 112, 112]              64
             ReLU6-6         [-1, 32, 112, 112]               0
            Conv2d-7         [-1, 16, 112, 112]             512
       BatchNorm2d-8         [-1, 16, 112, 112]              32
  InvertedResidual-9         [-1, 16, 112, 112]               0
           Conv2d-10         [-1, 96, 112, 112]           1,536
      BatchNorm2d-11         [-1, 96, 112, 112]             192
            ReLU6-12         [-1, 96, 112, 112]               0
           Conv2d-13           [-1, 96, 56, 56]             864
      BatchNorm2d-14           [-1, 96, 56, 56]             192
            ReLU6-15           [-1, 96, 56, 56]               0
           Conv2d-16           [-1, 24, 56, 56]           2,304
      BatchNorm2d-17           [-1, 24, 56, 56]              48
 InvertedResidual-18           [-1, 24, 56, 56]               0
           Conv2d-19          [-1, 144, 56, 56]           3,456
      BatchNorm2d-20          [-1, 144, 56, 56]             288
            ReLU6-21          [-1, 144, 56, 56]               0
           Conv2d-22          [-1, 144, 56, 56]           1,296
      BatchNorm2d-23          [-1, 144, 56, 56]             288
            ReLU6-24          [-1, 144, 56, 56]               0
           Conv2d-25           [-1, 24, 56, 56]           3,456
      BatchNorm2d-26           [-1, 24, 56, 56]              48
 InvertedResidual-27           [-1, 24, 56, 56]               0
           Conv2d-28          [-1, 144, 56, 56]           3,456
      BatchNorm2d-29          [-1, 144, 56, 56]             288
            ReLU6-30          [-1, 144, 56, 56]               0
           Conv2d-31          [-1, 144, 28, 28]           1,296
      BatchNorm2d-32          [-1, 144, 28, 28]             288
            ReLU6-33          [-1, 144, 28, 28]               0
           Conv2d-34           [-1, 32, 28, 28]           4,608
      BatchNorm2d-35           [-1, 32, 28, 28]              64
 InvertedResidual-36           [-1, 32, 28, 28]               0
           Conv2d-37          [-1, 192, 28, 28]           6,144
      BatchNorm2d-38          [-1, 192, 28, 28]             384
            ReLU6-39          [-1, 192, 28, 28]               0
           Conv2d-40          [-1, 192, 28, 28]           1,728
      BatchNorm2d-41          [-1, 192, 28, 28]             384
            ReLU6-42          [-1, 192, 28, 28]               0
           Conv2d-43           [-1, 32, 28, 28]           6,144
      BatchNorm2d-44           [-1, 32, 28, 28]              64
 InvertedResidual-45           [-1, 32, 28, 28]               0
           Conv2d-46          [-1, 192, 28, 28]           6,144
      BatchNorm2d-47          [-1, 192, 28, 28]             384
            ReLU6-48          [-1, 192, 28, 28]               0
           Conv2d-49          [-1, 192, 28, 28]           1,728
      BatchNorm2d-50          [-1, 192, 28, 28]             384
            ReLU6-51          [-1, 192, 28, 28]               0
           Conv2d-52           [-1, 32, 28, 28]           6,144
      BatchNorm2d-53           [-1, 32, 28, 28]              64
 InvertedResidual-54           [-1, 32, 28, 28]               0
           Conv2d-55          [-1, 192, 28, 28]           6,144
      BatchNorm2d-56          [-1, 192, 28, 28]             384
            ReLU6-57          [-1, 192, 28, 28]               0
           Conv2d-58          [-1, 192, 14, 14]           1,728
      BatchNorm2d-59          [-1, 192, 14, 14]             384
            ReLU6-60          [-1, 192, 14, 14]               0
           Conv2d-61           [-1, 64, 14, 14]          12,288
      BatchNorm2d-62           [-1, 64, 14, 14]             128
 InvertedResidual-63           [-1, 64, 14, 14]               0
           Conv2d-64          [-1, 384, 14, 14]          24,576
      BatchNorm2d-65          [-1, 384, 14, 14]             768
            ReLU6-66          [-1, 384, 14, 14]               0
           Conv2d-67          [-1, 384, 14, 14]           3,456
      BatchNorm2d-68          [-1, 384, 14, 14]             768
            ReLU6-69          [-1, 384, 14, 14]               0
           Conv2d-70           [-1, 64, 14, 14]          24,576
      BatchNorm2d-71           [-1, 64, 14, 14]             128
 InvertedResidual-72           [-1, 64, 14, 14]               0
           Conv2d-73          [-1, 384, 14, 14]          24,576
      BatchNorm2d-74          [-1, 384, 14, 14]             768
            ReLU6-75          [-1, 384, 14, 14]               0
           Conv2d-76          [-1, 384, 14, 14]           3,456
      BatchNorm2d-77          [-1, 384, 14, 14]             768
            ReLU6-78          [-1, 384, 14, 14]               0
           Conv2d-79           [-1, 64, 14, 14]          24,576
      BatchNorm2d-80           [-1, 64, 14, 14]             128
 InvertedResidual-81           [-1, 64, 14, 14]               0
           Conv2d-82          [-1, 384, 14, 14]          24,576
      BatchNorm2d-83          [-1, 384, 14, 14]             768
            ReLU6-84          [-1, 384, 14, 14]               0
           Conv2d-85          [-1, 384, 14, 14]           3,456
      BatchNorm2d-86          [-1, 384, 14, 14]             768
            ReLU6-87          [-1, 384, 14, 14]               0
           Conv2d-88           [-1, 64, 14, 14]          24,576
      BatchNorm2d-89           [-1, 64, 14, 14]             128
 InvertedResidual-90           [-1, 64, 14, 14]               0
           Conv2d-91          [-1, 384, 14, 14]          24,576
      BatchNorm2d-92          [-1, 384, 14, 14]             768
            ReLU6-93          [-1, 384, 14, 14]               0
           Conv2d-94          [-1, 384, 14, 14]           3,456
      BatchNorm2d-95          [-1, 384, 14, 14]             768
            ReLU6-96          [-1, 384, 14, 14]               0
           Conv2d-97           [-1, 96, 14, 14]          36,864
      BatchNorm2d-98           [-1, 96, 14, 14]             192
 InvertedResidual-99           [-1, 96, 14, 14]               0
          Conv2d-100          [-1, 576, 14, 14]          55,296
     BatchNorm2d-101          [-1, 576, 14, 14]           1,152
           ReLU6-102          [-1, 576, 14, 14]               0
          Conv2d-103          [-1, 576, 14, 14]           5,184
     BatchNorm2d-104          [-1, 576, 14, 14]           1,152
           ReLU6-105          [-1, 576, 14, 14]               0
          Conv2d-106           [-1, 96, 14, 14]          55,296
     BatchNorm2d-107           [-1, 96, 14, 14]             192
InvertedResidual-108           [-1, 96, 14, 14]               0
          Conv2d-109          [-1, 576, 14, 14]          55,296
     BatchNorm2d-110          [-1, 576, 14, 14]           1,152
           ReLU6-111          [-1, 576, 14, 14]               0
          Conv2d-112          [-1, 576, 14, 14]           5,184
     BatchNorm2d-113          [-1, 576, 14, 14]           1,152
           ReLU6-114          [-1, 576, 14, 14]               0
          Conv2d-115           [-1, 96, 14, 14]          55,296
     BatchNorm2d-116           [-1, 96, 14, 14]             192
InvertedResidual-117           [-1, 96, 14, 14]               0
          Conv2d-118          [-1, 576, 14, 14]          55,296
     BatchNorm2d-119          [-1, 576, 14, 14]           1,152
           ReLU6-120          [-1, 576, 14, 14]               0
          Conv2d-121            [-1, 576, 7, 7]           5,184
     BatchNorm2d-122            [-1, 576, 7, 7]           1,152
           ReLU6-123            [-1, 576, 7, 7]               0
          Conv2d-124            [-1, 160, 7, 7]          92,160
     BatchNorm2d-125            [-1, 160, 7, 7]             320
InvertedResidual-126            [-1, 160, 7, 7]               0
          Conv2d-127            [-1, 960, 7, 7]         153,600
     BatchNorm2d-128            [-1, 960, 7, 7]           1,920
           ReLU6-129            [-1, 960, 7, 7]               0
          Conv2d-130            [-1, 960, 7, 7]           8,640
     BatchNorm2d-131            [-1, 960, 7, 7]           1,920
           ReLU6-132            [-1, 960, 7, 7]               0
          Conv2d-133            [-1, 160, 7, 7]         153,600
     BatchNorm2d-134            [-1, 160, 7, 7]             320
InvertedResidual-135            [-1, 160, 7, 7]               0
          Conv2d-136            [-1, 960, 7, 7]         153,600
     BatchNorm2d-137            [-1, 960, 7, 7]           1,920
           ReLU6-138            [-1, 960, 7, 7]               0
          Conv2d-139            [-1, 960, 7, 7]           8,640
     BatchNorm2d-140            [-1, 960, 7, 7]           1,920
           ReLU6-141            [-1, 960, 7, 7]               0
          Conv2d-142            [-1, 160, 7, 7]         153,600
     BatchNorm2d-143            [-1, 160, 7, 7]             320
InvertedResidual-144            [-1, 160, 7, 7]               0
          Conv2d-145            [-1, 960, 7, 7]         153,600
     BatchNorm2d-146            [-1, 960, 7, 7]           1,920
           ReLU6-147            [-1, 960, 7, 7]               0
          Conv2d-148            [-1, 960, 7, 7]           8,640
     BatchNorm2d-149            [-1, 960, 7, 7]           1,920
           ReLU6-150            [-1, 960, 7, 7]               0
          Conv2d-151            [-1, 320, 7, 7]         307,200
     BatchNorm2d-152            [-1, 320, 7, 7]             640
InvertedResidual-153            [-1, 320, 7, 7]               0
          Conv2d-154           [-1, 1280, 7, 7]         409,600
     BatchNorm2d-155           [-1, 1280, 7, 7]           2,560
           ReLU6-156           [-1, 1280, 7, 7]               0
         Dropout-157                 [-1, 1280]               0
          Linear-158                   [-1, 10]          12,810
     MobileNetV2-159                   [-1, 10]               0
================================================================
Total params: 2,236,682
Trainable params: 12,810
Non-trainable params: 2,223,872
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 152.86
Params size (MB): 8.53
Estimated Total Size (MB): 161.97
----------------------------------------------------------------
</code></pre>
</div>
</div>
<div class="cell code" id="5bcec864" data-outputId="e4498dc7-8792-41ef-e79e-f10b88671bec">
<div class="sourceCode" id="cb48"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>freeze_mobilenet_v2_lion <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>mobilenet_v2,</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;Lion&#39;</span>,</span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>freeze_mobilenet_v2_lion.train()</span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a>freeze_mobilenet_v2_lion.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Обучение завершено!!!
Best accuracy: 0.7357
</code></pre>
</div>
<div class="output display_data">
<p><img src="c510c3e209fc6261ea774c3586c270dd4b44c017.png" /></p>
</div>
</div>
<div class="cell code" id="86a319ff" data-outputId="ebaf9c35-7429-4e39-9543-42ccf1489e46">
<div class="sourceCode" id="cb50"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a>mobilenet_v2 <span class="op">=</span> MobileNetFreeze(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>freeze_mobilenet_v2_adamw <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>mobilenet_v2,</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;AdamW&#39;</span>,</span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb50-6"><a href="#cb50-6" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb50-7"><a href="#cb50-7" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb50-8"><a href="#cb50-8" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">256</span>,</span>
<span id="cb50-9"><a href="#cb50-9" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb50-10"><a href="#cb50-10" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb50-11"><a href="#cb50-11" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb50-12"><a href="#cb50-12" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb50-13"><a href="#cb50-13" aria-hidden="true" tabindex="-1"></a>freeze_mobilenet_v2_adamw.train()</span>
<span id="cb50-14"><a href="#cb50-14" aria-hidden="true" tabindex="-1"></a>freeze_mobilenet_v2_adamw.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Обучение завершено!!!
Best accuracy: 0.6835
</code></pre>
</div>
<div class="output display_data">
<p><img src="696881c65e43edd1682fa7d5f9f6c6a69658ed1a.png" /></p>
</div>
</div>
<div class="cell markdown" id="736b65b9">
<p>Получили результат хуже, чем для ResNet</p>
</div>
<div class="cell code" id="8afe5ef3">
<div class="sourceCode" id="cb52"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> MobileNet(nn.Module):</span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_classes):</span>
<span id="cb52-3"><a href="#cb52-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(MobileNet, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb52-4"><a href="#cb52-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mobilenet_v2 <span class="op">=</span> models.mobilenet_v2( weights<span class="op">=</span><span class="st">&#39;DEFAULT&#39;</span>)</span>
<span id="cb52-5"><a href="#cb52-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-6"><a href="#cb52-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.mobilenet_v2.classifier[<span class="dv">1</span>] <span class="op">=</span> torch.nn.Linear(</span>
<span id="cb52-7"><a href="#cb52-7" aria-hidden="true" tabindex="-1"></a>            in_features<span class="op">=</span><span class="va">self</span>.mobilenet_v2.classifier[<span class="dv">1</span>].in_features,</span>
<span id="cb52-8"><a href="#cb52-8" aria-hidden="true" tabindex="-1"></a>            out_features<span class="op">=</span>num_classes)</span>
<span id="cb52-9"><a href="#cb52-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb52-10"><a href="#cb52-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb52-11"><a href="#cb52-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.mobilenet_v2(x)</span></code></pre></div>
</div>
<div class="cell code" id="dd90c437" data-outputId="0f8c1c31-34df-479c-fb05-ad9e26649643">
<div class="sourceCode" id="cb53"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>mobilenet_v2 <span class="op">=</span> MobileNet(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>mobilenet_v2 <span class="op">=</span> mobilenet_v2.to(device)</span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>summary(mobilenet_v2, input_size<span class="op">=</span>input_size)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 32, 112, 112]             864
       BatchNorm2d-2         [-1, 32, 112, 112]              64
             ReLU6-3         [-1, 32, 112, 112]               0
            Conv2d-4         [-1, 32, 112, 112]             288
       BatchNorm2d-5         [-1, 32, 112, 112]              64
             ReLU6-6         [-1, 32, 112, 112]               0
            Conv2d-7         [-1, 16, 112, 112]             512
       BatchNorm2d-8         [-1, 16, 112, 112]              32
  InvertedResidual-9         [-1, 16, 112, 112]               0
           Conv2d-10         [-1, 96, 112, 112]           1,536
      BatchNorm2d-11         [-1, 96, 112, 112]             192
            ReLU6-12         [-1, 96, 112, 112]               0
           Conv2d-13           [-1, 96, 56, 56]             864
      BatchNorm2d-14           [-1, 96, 56, 56]             192
            ReLU6-15           [-1, 96, 56, 56]               0
           Conv2d-16           [-1, 24, 56, 56]           2,304
      BatchNorm2d-17           [-1, 24, 56, 56]              48
 InvertedResidual-18           [-1, 24, 56, 56]               0
           Conv2d-19          [-1, 144, 56, 56]           3,456
      BatchNorm2d-20          [-1, 144, 56, 56]             288
            ReLU6-21          [-1, 144, 56, 56]               0
           Conv2d-22          [-1, 144, 56, 56]           1,296
      BatchNorm2d-23          [-1, 144, 56, 56]             288
            ReLU6-24          [-1, 144, 56, 56]               0
           Conv2d-25           [-1, 24, 56, 56]           3,456
      BatchNorm2d-26           [-1, 24, 56, 56]              48
 InvertedResidual-27           [-1, 24, 56, 56]               0
           Conv2d-28          [-1, 144, 56, 56]           3,456
      BatchNorm2d-29          [-1, 144, 56, 56]             288
            ReLU6-30          [-1, 144, 56, 56]               0
           Conv2d-31          [-1, 144, 28, 28]           1,296
      BatchNorm2d-32          [-1, 144, 28, 28]             288
            ReLU6-33          [-1, 144, 28, 28]               0
           Conv2d-34           [-1, 32, 28, 28]           4,608
      BatchNorm2d-35           [-1, 32, 28, 28]              64
 InvertedResidual-36           [-1, 32, 28, 28]               0
           Conv2d-37          [-1, 192, 28, 28]           6,144
      BatchNorm2d-38          [-1, 192, 28, 28]             384
            ReLU6-39          [-1, 192, 28, 28]               0
           Conv2d-40          [-1, 192, 28, 28]           1,728
      BatchNorm2d-41          [-1, 192, 28, 28]             384
            ReLU6-42          [-1, 192, 28, 28]               0
           Conv2d-43           [-1, 32, 28, 28]           6,144
      BatchNorm2d-44           [-1, 32, 28, 28]              64
 InvertedResidual-45           [-1, 32, 28, 28]               0
           Conv2d-46          [-1, 192, 28, 28]           6,144
      BatchNorm2d-47          [-1, 192, 28, 28]             384
            ReLU6-48          [-1, 192, 28, 28]               0
           Conv2d-49          [-1, 192, 28, 28]           1,728
      BatchNorm2d-50          [-1, 192, 28, 28]             384
            ReLU6-51          [-1, 192, 28, 28]               0
           Conv2d-52           [-1, 32, 28, 28]           6,144
      BatchNorm2d-53           [-1, 32, 28, 28]              64
 InvertedResidual-54           [-1, 32, 28, 28]               0
           Conv2d-55          [-1, 192, 28, 28]           6,144
      BatchNorm2d-56          [-1, 192, 28, 28]             384
            ReLU6-57          [-1, 192, 28, 28]               0
           Conv2d-58          [-1, 192, 14, 14]           1,728
      BatchNorm2d-59          [-1, 192, 14, 14]             384
            ReLU6-60          [-1, 192, 14, 14]               0
           Conv2d-61           [-1, 64, 14, 14]          12,288
      BatchNorm2d-62           [-1, 64, 14, 14]             128
 InvertedResidual-63           [-1, 64, 14, 14]               0
           Conv2d-64          [-1, 384, 14, 14]          24,576
      BatchNorm2d-65          [-1, 384, 14, 14]             768
            ReLU6-66          [-1, 384, 14, 14]               0
           Conv2d-67          [-1, 384, 14, 14]           3,456
      BatchNorm2d-68          [-1, 384, 14, 14]             768
            ReLU6-69          [-1, 384, 14, 14]               0
           Conv2d-70           [-1, 64, 14, 14]          24,576
      BatchNorm2d-71           [-1, 64, 14, 14]             128
 InvertedResidual-72           [-1, 64, 14, 14]               0
           Conv2d-73          [-1, 384, 14, 14]          24,576
      BatchNorm2d-74          [-1, 384, 14, 14]             768
            ReLU6-75          [-1, 384, 14, 14]               0
           Conv2d-76          [-1, 384, 14, 14]           3,456
      BatchNorm2d-77          [-1, 384, 14, 14]             768
            ReLU6-78          [-1, 384, 14, 14]               0
           Conv2d-79           [-1, 64, 14, 14]          24,576
      BatchNorm2d-80           [-1, 64, 14, 14]             128
 InvertedResidual-81           [-1, 64, 14, 14]               0
           Conv2d-82          [-1, 384, 14, 14]          24,576
      BatchNorm2d-83          [-1, 384, 14, 14]             768
            ReLU6-84          [-1, 384, 14, 14]               0
           Conv2d-85          [-1, 384, 14, 14]           3,456
      BatchNorm2d-86          [-1, 384, 14, 14]             768
            ReLU6-87          [-1, 384, 14, 14]               0
           Conv2d-88           [-1, 64, 14, 14]          24,576
      BatchNorm2d-89           [-1, 64, 14, 14]             128
 InvertedResidual-90           [-1, 64, 14, 14]               0
           Conv2d-91          [-1, 384, 14, 14]          24,576
      BatchNorm2d-92          [-1, 384, 14, 14]             768
            ReLU6-93          [-1, 384, 14, 14]               0
           Conv2d-94          [-1, 384, 14, 14]           3,456
      BatchNorm2d-95          [-1, 384, 14, 14]             768
            ReLU6-96          [-1, 384, 14, 14]               0
           Conv2d-97           [-1, 96, 14, 14]          36,864
      BatchNorm2d-98           [-1, 96, 14, 14]             192
 InvertedResidual-99           [-1, 96, 14, 14]               0
          Conv2d-100          [-1, 576, 14, 14]          55,296
     BatchNorm2d-101          [-1, 576, 14, 14]           1,152
           ReLU6-102          [-1, 576, 14, 14]               0
          Conv2d-103          [-1, 576, 14, 14]           5,184
     BatchNorm2d-104          [-1, 576, 14, 14]           1,152
           ReLU6-105          [-1, 576, 14, 14]               0
          Conv2d-106           [-1, 96, 14, 14]          55,296
     BatchNorm2d-107           [-1, 96, 14, 14]             192
InvertedResidual-108           [-1, 96, 14, 14]               0
          Conv2d-109          [-1, 576, 14, 14]          55,296
     BatchNorm2d-110          [-1, 576, 14, 14]           1,152
           ReLU6-111          [-1, 576, 14, 14]               0
          Conv2d-112          [-1, 576, 14, 14]           5,184
     BatchNorm2d-113          [-1, 576, 14, 14]           1,152
           ReLU6-114          [-1, 576, 14, 14]               0
          Conv2d-115           [-1, 96, 14, 14]          55,296
     BatchNorm2d-116           [-1, 96, 14, 14]             192
InvertedResidual-117           [-1, 96, 14, 14]               0
          Conv2d-118          [-1, 576, 14, 14]          55,296
     BatchNorm2d-119          [-1, 576, 14, 14]           1,152
           ReLU6-120          [-1, 576, 14, 14]               0
          Conv2d-121            [-1, 576, 7, 7]           5,184
     BatchNorm2d-122            [-1, 576, 7, 7]           1,152
           ReLU6-123            [-1, 576, 7, 7]               0
          Conv2d-124            [-1, 160, 7, 7]          92,160
     BatchNorm2d-125            [-1, 160, 7, 7]             320
InvertedResidual-126            [-1, 160, 7, 7]               0
          Conv2d-127            [-1, 960, 7, 7]         153,600
     BatchNorm2d-128            [-1, 960, 7, 7]           1,920
           ReLU6-129            [-1, 960, 7, 7]               0
          Conv2d-130            [-1, 960, 7, 7]           8,640
     BatchNorm2d-131            [-1, 960, 7, 7]           1,920
           ReLU6-132            [-1, 960, 7, 7]               0
          Conv2d-133            [-1, 160, 7, 7]         153,600
     BatchNorm2d-134            [-1, 160, 7, 7]             320
InvertedResidual-135            [-1, 160, 7, 7]               0
          Conv2d-136            [-1, 960, 7, 7]         153,600
     BatchNorm2d-137            [-1, 960, 7, 7]           1,920
           ReLU6-138            [-1, 960, 7, 7]               0
          Conv2d-139            [-1, 960, 7, 7]           8,640
     BatchNorm2d-140            [-1, 960, 7, 7]           1,920
           ReLU6-141            [-1, 960, 7, 7]               0
          Conv2d-142            [-1, 160, 7, 7]         153,600
     BatchNorm2d-143            [-1, 160, 7, 7]             320
InvertedResidual-144            [-1, 160, 7, 7]               0
          Conv2d-145            [-1, 960, 7, 7]         153,600
     BatchNorm2d-146            [-1, 960, 7, 7]           1,920
           ReLU6-147            [-1, 960, 7, 7]               0
          Conv2d-148            [-1, 960, 7, 7]           8,640
     BatchNorm2d-149            [-1, 960, 7, 7]           1,920
           ReLU6-150            [-1, 960, 7, 7]               0
          Conv2d-151            [-1, 320, 7, 7]         307,200
     BatchNorm2d-152            [-1, 320, 7, 7]             640
InvertedResidual-153            [-1, 320, 7, 7]               0
          Conv2d-154           [-1, 1280, 7, 7]         409,600
     BatchNorm2d-155           [-1, 1280, 7, 7]           2,560
           ReLU6-156           [-1, 1280, 7, 7]               0
         Dropout-157                 [-1, 1280]               0
          Linear-158                   [-1, 10]          12,810
     MobileNetV2-159                   [-1, 10]               0
================================================================
Total params: 2,236,682
Trainable params: 2,236,682
Non-trainable params: 0
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 152.86
Params size (MB): 8.53
Estimated Total Size (MB): 161.97
----------------------------------------------------------------
</code></pre>
</div>
</div>
<div class="cell code" id="32cc1459">
<div class="sourceCode" id="cb55"><pre class="sourceCode python"><code class="sourceCode python"></code></pre></div>
</div>
<div class="cell code" id="15e7612a" data-outputId="d387d304-93ab-4441-bb76-257f0e04d99f">
<div class="sourceCode" id="cb56"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a>trainer_mobilenet_v2_lion <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>mobilenet_v2,</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;Lion&#39;</span>,</span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb56-7"><a href="#cb56-7" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb56-8"><a href="#cb56-8" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb56-9"><a href="#cb56-9" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb56-10"><a href="#cb56-10" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb56-11"><a href="#cb56-11" aria-hidden="true" tabindex="-1"></a>trainer_mobilenet_v2_lion.train()</span>
<span id="cb56-12"><a href="#cb56-12" aria-hidden="true" tabindex="-1"></a>trainer_mobilenet_v2_lion.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Обучение завершено!!!
Best accuracy: 0.9496
</code></pre>
</div>
<div class="output display_data">
<p><img src="fa563d861575a2094cce2243039bd67be0b49184.png" /></p>
</div>
</div>
<div class="cell code" id="fe05d719" data-outputId="a104209d-794d-474c-bf4b-4b40701ea4ce">
<div class="sourceCode" id="cb58"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a>mobilenet_v2 <span class="op">=</span> MobileNet(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>trainer_mobilenet_v2_adamw <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>mobilenet_v2,</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;AdamW&#39;</span>,</span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb58-6"><a href="#cb58-6" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb58-7"><a href="#cb58-7" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb58-8"><a href="#cb58-8" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb58-9"><a href="#cb58-9" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb58-10"><a href="#cb58-10" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb58-11"><a href="#cb58-11" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb58-12"><a href="#cb58-12" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb58-13"><a href="#cb58-13" aria-hidden="true" tabindex="-1"></a>trainer_mobilenet_v2_adamw.train()</span>
<span id="cb58-14"><a href="#cb58-14" aria-hidden="true" tabindex="-1"></a>trainer_mobilenet_v2_adamw.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Обучение завершено!!!
Best accuracy: 0.9389
</code></pre>
</div>
<div class="output display_data">
<p><img src="2279f68cf9980182766ffa00779be7c8da835c13.png" /></p>
</div>
</div>
<div class="cell markdown" id="cdc8e343">
<p>Для finetuning мы получили сопоставимый результат с ResNet. Но обратим внимание, что у ResNet34 было <strong>21 289 802</strong> обучаемых параметров, в то время как у MobileNetV2 <strong>2 236 682</strong></p>
<p>Далее у нас на очереди модель 2020 года. В данном случае в связи с тем, что полный finetuning модели занимает несколько часов, то мы обучим с freeze всех слоев. Единственное изменим слой классификации в первый раз на линейный слой, а второй раз на</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a>nn.Sequential(</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.5</span>),</span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.efficientnet_v2_m.classifier[<span class="dv">2</span>].in_features, <span class="dv">1024</span>),</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="dv">1024</span>),</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>            nn.PReLU(),</span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.5</span>),</span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">1024</span>, num_classes))</span></code></pre></div>
<p>И посмотрим на метрики</p>
</div>
<section id="efficientnetv2" class="cell markdown" id="03bfeeec">
<h3>EfficientNetv2</h3>
</section>
<div class="cell code" id="830beb39">
<div class="sourceCode" id="cb61"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EfficientNet(nn.Module):</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_classes):</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(EfficientNet, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.efficientnet_v2_m <span class="op">=</span> models.convnext_base(weights<span class="op">=</span><span class="st">&#39;DEFAULT&#39;</span>)</span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> param <span class="kw">in</span> <span class="va">self</span>.efficientnet_v2_m.parameters(): param.requires_grad <span class="op">=</span> <span class="va">False</span></span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.efficientnet_v2_m.classifier[<span class="dv">2</span>] <span class="op">=</span> torch.nn.Linear(</span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>            in_features<span class="op">=</span><span class="va">self</span>.efficientnet_v2_m.classifier[<span class="dv">2</span>].in_features,</span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>            out_features<span class="op">=</span>num_classes)</span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.efficientnet_v2_m(x)</span></code></pre></div>
</div>
<div class="cell code" id="082a7dc2" data-outputId="ced2a68e-acf0-4c92-bca2-ec12473f742c">
<div class="sourceCode" id="cb62"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a>input_size <span class="op">=</span> (<span class="dv">3</span>, <span class="dv">224</span>, <span class="dv">224</span>)</span>
<span id="cb62-2"><a href="#cb62-2" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">&quot;cuda&quot;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span>)</span>
<span id="cb62-3"><a href="#cb62-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-4"><a href="#cb62-4" aria-hidden="true" tabindex="-1"></a>efficientnet_v2_m <span class="op">=</span> EfficientNet(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb62-5"><a href="#cb62-5" aria-hidden="true" tabindex="-1"></a>efficientnet_v2_m <span class="op">=</span> efficientnet_v2_m.to(device)</span>
<span id="cb62-6"><a href="#cb62-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-7"><a href="#cb62-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb62-8"><a href="#cb62-8" aria-hidden="true" tabindex="-1"></a>summary(efficientnet_v2_m, input_size<span class="op">=</span>input_size)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 128, 56, 56]           6,272
       LayerNorm2d-2          [-1, 128, 56, 56]             256
            Conv2d-3          [-1, 128, 56, 56]           6,400
           Permute-4          [-1, 56, 56, 128]               0
         LayerNorm-5          [-1, 56, 56, 128]             256
            Linear-6          [-1, 56, 56, 512]          66,048
              GELU-7          [-1, 56, 56, 512]               0
            Linear-8          [-1, 56, 56, 128]          65,664
           Permute-9          [-1, 128, 56, 56]               0
  StochasticDepth-10          [-1, 128, 56, 56]               0
          CNBlock-11          [-1, 128, 56, 56]               0
           Conv2d-12          [-1, 128, 56, 56]           6,400
          Permute-13          [-1, 56, 56, 128]               0
        LayerNorm-14          [-1, 56, 56, 128]             256
           Linear-15          [-1, 56, 56, 512]          66,048
             GELU-16          [-1, 56, 56, 512]               0
           Linear-17          [-1, 56, 56, 128]          65,664
          Permute-18          [-1, 128, 56, 56]               0
  StochasticDepth-19          [-1, 128, 56, 56]               0
          CNBlock-20          [-1, 128, 56, 56]               0
           Conv2d-21          [-1, 128, 56, 56]           6,400
          Permute-22          [-1, 56, 56, 128]               0
        LayerNorm-23          [-1, 56, 56, 128]             256
           Linear-24          [-1, 56, 56, 512]          66,048
             GELU-25          [-1, 56, 56, 512]               0
           Linear-26          [-1, 56, 56, 128]          65,664
          Permute-27          [-1, 128, 56, 56]               0
  StochasticDepth-28          [-1, 128, 56, 56]               0
          CNBlock-29          [-1, 128, 56, 56]               0
      LayerNorm2d-30          [-1, 128, 56, 56]             256
           Conv2d-31          [-1, 256, 28, 28]         131,328
           Conv2d-32          [-1, 256, 28, 28]          12,800
          Permute-33          [-1, 28, 28, 256]               0
        LayerNorm-34          [-1, 28, 28, 256]             512
           Linear-35         [-1, 28, 28, 1024]         263,168
             GELU-36         [-1, 28, 28, 1024]               0
           Linear-37          [-1, 28, 28, 256]         262,400
          Permute-38          [-1, 256, 28, 28]               0
  StochasticDepth-39          [-1, 256, 28, 28]               0
          CNBlock-40          [-1, 256, 28, 28]               0
           Conv2d-41          [-1, 256, 28, 28]          12,800
          Permute-42          [-1, 28, 28, 256]               0
        LayerNorm-43          [-1, 28, 28, 256]             512
           Linear-44         [-1, 28, 28, 1024]         263,168
             GELU-45         [-1, 28, 28, 1024]               0
           Linear-46          [-1, 28, 28, 256]         262,400
          Permute-47          [-1, 256, 28, 28]               0
  StochasticDepth-48          [-1, 256, 28, 28]               0
          CNBlock-49          [-1, 256, 28, 28]               0
           Conv2d-50          [-1, 256, 28, 28]          12,800
          Permute-51          [-1, 28, 28, 256]               0
        LayerNorm-52          [-1, 28, 28, 256]             512
           Linear-53         [-1, 28, 28, 1024]         263,168
             GELU-54         [-1, 28, 28, 1024]               0
           Linear-55          [-1, 28, 28, 256]         262,400
          Permute-56          [-1, 256, 28, 28]               0
  StochasticDepth-57          [-1, 256, 28, 28]               0
          CNBlock-58          [-1, 256, 28, 28]               0
      LayerNorm2d-59          [-1, 256, 28, 28]             512
           Conv2d-60          [-1, 512, 14, 14]         524,800
           Conv2d-61          [-1, 512, 14, 14]          25,600
          Permute-62          [-1, 14, 14, 512]               0
        LayerNorm-63          [-1, 14, 14, 512]           1,024
           Linear-64         [-1, 14, 14, 2048]       1,050,624
             GELU-65         [-1, 14, 14, 2048]               0
           Linear-66          [-1, 14, 14, 512]       1,049,088
          Permute-67          [-1, 512, 14, 14]               0
  StochasticDepth-68          [-1, 512, 14, 14]               0
          CNBlock-69          [-1, 512, 14, 14]               0
           Conv2d-70          [-1, 512, 14, 14]          25,600
          Permute-71          [-1, 14, 14, 512]               0
        LayerNorm-72          [-1, 14, 14, 512]           1,024
           Linear-73         [-1, 14, 14, 2048]       1,050,624
             GELU-74         [-1, 14, 14, 2048]               0
           Linear-75          [-1, 14, 14, 512]       1,049,088
          Permute-76          [-1, 512, 14, 14]               0
  StochasticDepth-77          [-1, 512, 14, 14]               0
          CNBlock-78          [-1, 512, 14, 14]               0
           Conv2d-79          [-1, 512, 14, 14]          25,600
          Permute-80          [-1, 14, 14, 512]               0
        LayerNorm-81          [-1, 14, 14, 512]           1,024
           Linear-82         [-1, 14, 14, 2048]       1,050,624
             GELU-83         [-1, 14, 14, 2048]               0
           Linear-84          [-1, 14, 14, 512]       1,049,088
          Permute-85          [-1, 512, 14, 14]               0
  StochasticDepth-86          [-1, 512, 14, 14]               0
          CNBlock-87          [-1, 512, 14, 14]               0
           Conv2d-88          [-1, 512, 14, 14]          25,600
          Permute-89          [-1, 14, 14, 512]               0
        LayerNorm-90          [-1, 14, 14, 512]           1,024
           Linear-91         [-1, 14, 14, 2048]       1,050,624
             GELU-92         [-1, 14, 14, 2048]               0
           Linear-93          [-1, 14, 14, 512]       1,049,088
          Permute-94          [-1, 512, 14, 14]               0
  StochasticDepth-95          [-1, 512, 14, 14]               0
          CNBlock-96          [-1, 512, 14, 14]               0
           Conv2d-97          [-1, 512, 14, 14]          25,600
          Permute-98          [-1, 14, 14, 512]               0
        LayerNorm-99          [-1, 14, 14, 512]           1,024
          Linear-100         [-1, 14, 14, 2048]       1,050,624
            GELU-101         [-1, 14, 14, 2048]               0
          Linear-102          [-1, 14, 14, 512]       1,049,088
         Permute-103          [-1, 512, 14, 14]               0
 StochasticDepth-104          [-1, 512, 14, 14]               0
         CNBlock-105          [-1, 512, 14, 14]               0
          Conv2d-106          [-1, 512, 14, 14]          25,600
         Permute-107          [-1, 14, 14, 512]               0
       LayerNorm-108          [-1, 14, 14, 512]           1,024
          Linear-109         [-1, 14, 14, 2048]       1,050,624
            GELU-110         [-1, 14, 14, 2048]               0
          Linear-111          [-1, 14, 14, 512]       1,049,088
         Permute-112          [-1, 512, 14, 14]               0
 StochasticDepth-113          [-1, 512, 14, 14]               0
         CNBlock-114          [-1, 512, 14, 14]               0
          Conv2d-115          [-1, 512, 14, 14]          25,600
         Permute-116          [-1, 14, 14, 512]               0
       LayerNorm-117          [-1, 14, 14, 512]           1,024
          Linear-118         [-1, 14, 14, 2048]       1,050,624
            GELU-119         [-1, 14, 14, 2048]               0
          Linear-120          [-1, 14, 14, 512]       1,049,088
         Permute-121          [-1, 512, 14, 14]               0
 StochasticDepth-122          [-1, 512, 14, 14]               0
         CNBlock-123          [-1, 512, 14, 14]               0
          Conv2d-124          [-1, 512, 14, 14]          25,600
         Permute-125          [-1, 14, 14, 512]               0
       LayerNorm-126          [-1, 14, 14, 512]           1,024
          Linear-127         [-1, 14, 14, 2048]       1,050,624
            GELU-128         [-1, 14, 14, 2048]               0
          Linear-129          [-1, 14, 14, 512]       1,049,088
         Permute-130          [-1, 512, 14, 14]               0
 StochasticDepth-131          [-1, 512, 14, 14]               0
         CNBlock-132          [-1, 512, 14, 14]               0
          Conv2d-133          [-1, 512, 14, 14]          25,600
         Permute-134          [-1, 14, 14, 512]               0
       LayerNorm-135          [-1, 14, 14, 512]           1,024
          Linear-136         [-1, 14, 14, 2048]       1,050,624
            GELU-137         [-1, 14, 14, 2048]               0
          Linear-138          [-1, 14, 14, 512]       1,049,088
         Permute-139          [-1, 512, 14, 14]               0
 StochasticDepth-140          [-1, 512, 14, 14]               0
         CNBlock-141          [-1, 512, 14, 14]               0
          Conv2d-142          [-1, 512, 14, 14]          25,600
         Permute-143          [-1, 14, 14, 512]               0
       LayerNorm-144          [-1, 14, 14, 512]           1,024
          Linear-145         [-1, 14, 14, 2048]       1,050,624
            GELU-146         [-1, 14, 14, 2048]               0
          Linear-147          [-1, 14, 14, 512]       1,049,088
         Permute-148          [-1, 512, 14, 14]               0
 StochasticDepth-149          [-1, 512, 14, 14]               0
         CNBlock-150          [-1, 512, 14, 14]               0
          Conv2d-151          [-1, 512, 14, 14]          25,600
         Permute-152          [-1, 14, 14, 512]               0
       LayerNorm-153          [-1, 14, 14, 512]           1,024
          Linear-154         [-1, 14, 14, 2048]       1,050,624
            GELU-155         [-1, 14, 14, 2048]               0
          Linear-156          [-1, 14, 14, 512]       1,049,088
         Permute-157          [-1, 512, 14, 14]               0
 StochasticDepth-158          [-1, 512, 14, 14]               0
         CNBlock-159          [-1, 512, 14, 14]               0
          Conv2d-160          [-1, 512, 14, 14]          25,600
         Permute-161          [-1, 14, 14, 512]               0
       LayerNorm-162          [-1, 14, 14, 512]           1,024
          Linear-163         [-1, 14, 14, 2048]       1,050,624
            GELU-164         [-1, 14, 14, 2048]               0
          Linear-165          [-1, 14, 14, 512]       1,049,088
         Permute-166          [-1, 512, 14, 14]               0
 StochasticDepth-167          [-1, 512, 14, 14]               0
         CNBlock-168          [-1, 512, 14, 14]               0
          Conv2d-169          [-1, 512, 14, 14]          25,600
         Permute-170          [-1, 14, 14, 512]               0
       LayerNorm-171          [-1, 14, 14, 512]           1,024
          Linear-172         [-1, 14, 14, 2048]       1,050,624
            GELU-173         [-1, 14, 14, 2048]               0
          Linear-174          [-1, 14, 14, 512]       1,049,088
         Permute-175          [-1, 512, 14, 14]               0
 StochasticDepth-176          [-1, 512, 14, 14]               0
         CNBlock-177          [-1, 512, 14, 14]               0
          Conv2d-178          [-1, 512, 14, 14]          25,600
         Permute-179          [-1, 14, 14, 512]               0
       LayerNorm-180          [-1, 14, 14, 512]           1,024
          Linear-181         [-1, 14, 14, 2048]       1,050,624
            GELU-182         [-1, 14, 14, 2048]               0
          Linear-183          [-1, 14, 14, 512]       1,049,088
         Permute-184          [-1, 512, 14, 14]               0
 StochasticDepth-185          [-1, 512, 14, 14]               0
         CNBlock-186          [-1, 512, 14, 14]               0
          Conv2d-187          [-1, 512, 14, 14]          25,600
         Permute-188          [-1, 14, 14, 512]               0
       LayerNorm-189          [-1, 14, 14, 512]           1,024
          Linear-190         [-1, 14, 14, 2048]       1,050,624
            GELU-191         [-1, 14, 14, 2048]               0
          Linear-192          [-1, 14, 14, 512]       1,049,088
         Permute-193          [-1, 512, 14, 14]               0
 StochasticDepth-194          [-1, 512, 14, 14]               0
         CNBlock-195          [-1, 512, 14, 14]               0
          Conv2d-196          [-1, 512, 14, 14]          25,600
         Permute-197          [-1, 14, 14, 512]               0
       LayerNorm-198          [-1, 14, 14, 512]           1,024
          Linear-199         [-1, 14, 14, 2048]       1,050,624
            GELU-200         [-1, 14, 14, 2048]               0
          Linear-201          [-1, 14, 14, 512]       1,049,088
         Permute-202          [-1, 512, 14, 14]               0
 StochasticDepth-203          [-1, 512, 14, 14]               0
         CNBlock-204          [-1, 512, 14, 14]               0
          Conv2d-205          [-1, 512, 14, 14]          25,600
         Permute-206          [-1, 14, 14, 512]               0
       LayerNorm-207          [-1, 14, 14, 512]           1,024
          Linear-208         [-1, 14, 14, 2048]       1,050,624
            GELU-209         [-1, 14, 14, 2048]               0
          Linear-210          [-1, 14, 14, 512]       1,049,088
         Permute-211          [-1, 512, 14, 14]               0
 StochasticDepth-212          [-1, 512, 14, 14]               0
         CNBlock-213          [-1, 512, 14, 14]               0
          Conv2d-214          [-1, 512, 14, 14]          25,600
         Permute-215          [-1, 14, 14, 512]               0
       LayerNorm-216          [-1, 14, 14, 512]           1,024
          Linear-217         [-1, 14, 14, 2048]       1,050,624
            GELU-218         [-1, 14, 14, 2048]               0
          Linear-219          [-1, 14, 14, 512]       1,049,088
         Permute-220          [-1, 512, 14, 14]               0
 StochasticDepth-221          [-1, 512, 14, 14]               0
         CNBlock-222          [-1, 512, 14, 14]               0
          Conv2d-223          [-1, 512, 14, 14]          25,600
         Permute-224          [-1, 14, 14, 512]               0
       LayerNorm-225          [-1, 14, 14, 512]           1,024
          Linear-226         [-1, 14, 14, 2048]       1,050,624
            GELU-227         [-1, 14, 14, 2048]               0
          Linear-228          [-1, 14, 14, 512]       1,049,088
         Permute-229          [-1, 512, 14, 14]               0
 StochasticDepth-230          [-1, 512, 14, 14]               0
         CNBlock-231          [-1, 512, 14, 14]               0
          Conv2d-232          [-1, 512, 14, 14]          25,600
         Permute-233          [-1, 14, 14, 512]               0
       LayerNorm-234          [-1, 14, 14, 512]           1,024
          Linear-235         [-1, 14, 14, 2048]       1,050,624
            GELU-236         [-1, 14, 14, 2048]               0
          Linear-237          [-1, 14, 14, 512]       1,049,088
         Permute-238          [-1, 512, 14, 14]               0
 StochasticDepth-239          [-1, 512, 14, 14]               0
         CNBlock-240          [-1, 512, 14, 14]               0
          Conv2d-241          [-1, 512, 14, 14]          25,600
         Permute-242          [-1, 14, 14, 512]               0
       LayerNorm-243          [-1, 14, 14, 512]           1,024
          Linear-244         [-1, 14, 14, 2048]       1,050,624
            GELU-245         [-1, 14, 14, 2048]               0
          Linear-246          [-1, 14, 14, 512]       1,049,088
         Permute-247          [-1, 512, 14, 14]               0
 StochasticDepth-248          [-1, 512, 14, 14]               0
         CNBlock-249          [-1, 512, 14, 14]               0
          Conv2d-250          [-1, 512, 14, 14]          25,600
         Permute-251          [-1, 14, 14, 512]               0
       LayerNorm-252          [-1, 14, 14, 512]           1,024
          Linear-253         [-1, 14, 14, 2048]       1,050,624
            GELU-254         [-1, 14, 14, 2048]               0
          Linear-255          [-1, 14, 14, 512]       1,049,088
         Permute-256          [-1, 512, 14, 14]               0
 StochasticDepth-257          [-1, 512, 14, 14]               0
         CNBlock-258          [-1, 512, 14, 14]               0
          Conv2d-259          [-1, 512, 14, 14]          25,600
         Permute-260          [-1, 14, 14, 512]               0
       LayerNorm-261          [-1, 14, 14, 512]           1,024
          Linear-262         [-1, 14, 14, 2048]       1,050,624
            GELU-263         [-1, 14, 14, 2048]               0
          Linear-264          [-1, 14, 14, 512]       1,049,088
         Permute-265          [-1, 512, 14, 14]               0
 StochasticDepth-266          [-1, 512, 14, 14]               0
         CNBlock-267          [-1, 512, 14, 14]               0
          Conv2d-268          [-1, 512, 14, 14]          25,600
         Permute-269          [-1, 14, 14, 512]               0
       LayerNorm-270          [-1, 14, 14, 512]           1,024
          Linear-271         [-1, 14, 14, 2048]       1,050,624
            GELU-272         [-1, 14, 14, 2048]               0
          Linear-273          [-1, 14, 14, 512]       1,049,088
         Permute-274          [-1, 512, 14, 14]               0
 StochasticDepth-275          [-1, 512, 14, 14]               0
         CNBlock-276          [-1, 512, 14, 14]               0
          Conv2d-277          [-1, 512, 14, 14]          25,600
         Permute-278          [-1, 14, 14, 512]               0
       LayerNorm-279          [-1, 14, 14, 512]           1,024
          Linear-280         [-1, 14, 14, 2048]       1,050,624
            GELU-281         [-1, 14, 14, 2048]               0
          Linear-282          [-1, 14, 14, 512]       1,049,088
         Permute-283          [-1, 512, 14, 14]               0
 StochasticDepth-284          [-1, 512, 14, 14]               0
         CNBlock-285          [-1, 512, 14, 14]               0
          Conv2d-286          [-1, 512, 14, 14]          25,600
         Permute-287          [-1, 14, 14, 512]               0
       LayerNorm-288          [-1, 14, 14, 512]           1,024
          Linear-289         [-1, 14, 14, 2048]       1,050,624
            GELU-290         [-1, 14, 14, 2048]               0
          Linear-291          [-1, 14, 14, 512]       1,049,088
         Permute-292          [-1, 512, 14, 14]               0
 StochasticDepth-293          [-1, 512, 14, 14]               0
         CNBlock-294          [-1, 512, 14, 14]               0
          Conv2d-295          [-1, 512, 14, 14]          25,600
         Permute-296          [-1, 14, 14, 512]               0
       LayerNorm-297          [-1, 14, 14, 512]           1,024
          Linear-298         [-1, 14, 14, 2048]       1,050,624
            GELU-299         [-1, 14, 14, 2048]               0
          Linear-300          [-1, 14, 14, 512]       1,049,088
         Permute-301          [-1, 512, 14, 14]               0
 StochasticDepth-302          [-1, 512, 14, 14]               0
         CNBlock-303          [-1, 512, 14, 14]               0
     LayerNorm2d-304          [-1, 512, 14, 14]           1,024
          Conv2d-305           [-1, 1024, 7, 7]       2,098,176
          Conv2d-306           [-1, 1024, 7, 7]          51,200
         Permute-307           [-1, 7, 7, 1024]               0
       LayerNorm-308           [-1, 7, 7, 1024]           2,048
          Linear-309           [-1, 7, 7, 4096]       4,198,400
            GELU-310           [-1, 7, 7, 4096]               0
          Linear-311           [-1, 7, 7, 1024]       4,195,328
         Permute-312           [-1, 1024, 7, 7]               0
 StochasticDepth-313           [-1, 1024, 7, 7]               0
         CNBlock-314           [-1, 1024, 7, 7]               0
          Conv2d-315           [-1, 1024, 7, 7]          51,200
         Permute-316           [-1, 7, 7, 1024]               0
       LayerNorm-317           [-1, 7, 7, 1024]           2,048
          Linear-318           [-1, 7, 7, 4096]       4,198,400
            GELU-319           [-1, 7, 7, 4096]               0
          Linear-320           [-1, 7, 7, 1024]       4,195,328
         Permute-321           [-1, 1024, 7, 7]               0
 StochasticDepth-322           [-1, 1024, 7, 7]               0
         CNBlock-323           [-1, 1024, 7, 7]               0
          Conv2d-324           [-1, 1024, 7, 7]          51,200
         Permute-325           [-1, 7, 7, 1024]               0
       LayerNorm-326           [-1, 7, 7, 1024]           2,048
          Linear-327           [-1, 7, 7, 4096]       4,198,400
            GELU-328           [-1, 7, 7, 4096]               0
          Linear-329           [-1, 7, 7, 1024]       4,195,328
         Permute-330           [-1, 1024, 7, 7]               0
 StochasticDepth-331           [-1, 1024, 7, 7]               0
         CNBlock-332           [-1, 1024, 7, 7]               0
AdaptiveAvgPool2d-333           [-1, 1024, 1, 1]               0
     LayerNorm2d-334           [-1, 1024, 1, 1]           2,048
         Flatten-335                 [-1, 1024]               0
          Linear-336                   [-1, 10]          10,250
        ConvNeXt-337                   [-1, 10]               0
================================================================
Total params: 87,558,666
Trainable params: 10,250
Non-trainable params: 87,548,416
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 548.21
Params size (MB): 334.01
Estimated Total Size (MB): 882.80
----------------------------------------------------------------
</code></pre>
</div>
</div>
<div class="cell code" id="57a2630d" data-outputId="667f6394-6a2f-4e0c-c304-bf6d2d32a92d">
<div class="sourceCode" id="cb64"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a>trainer_efficientnet_v2_m_lion <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>efficientnet_v2_m,</span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;Lion&#39;</span>,</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb64-11"><a href="#cb64-11" aria-hidden="true" tabindex="-1"></a>trainer_efficientnet_v2_m_lion.train()</span>
<span id="cb64-12"><a href="#cb64-12" aria-hidden="true" tabindex="-1"></a>trainer_efficientnet_v2_m_lion.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Обучение завершено!!!
Best accuracy: 0.9484
</code></pre>
</div>
<div class="output display_data">
<p><img src="b19c3a5e11f9a57931e82fd1179f73ba9da150f5.png" /></p>
</div>
</div>
<div class="cell code" id="b5a3b4a7">
<div class="sourceCode" id="cb66"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> EfficientNetV2(nn.Module):</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, num_classes):</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(EfficientNetV2, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.efficientnet_v2_m <span class="op">=</span> models.convnext_base(weights<span class="op">=</span><span class="st">&#39;DEFAULT&#39;</span>)</span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> param <span class="kw">in</span> <span class="va">self</span>.efficientnet_v2_m.parameters(): param.requires_grad <span class="op">=</span> <span class="va">False</span></span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.efficientnet_v2_m.classifier[<span class="dv">2</span>] <span class="op">=</span> nn.Sequential(</span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.5</span>),</span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="va">self</span>.efficientnet_v2_m.classifier[<span class="dv">2</span>].in_features, <span class="dv">1024</span>),</span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a>            nn.BatchNorm1d(<span class="dv">1024</span>),</span>
<span id="cb66-11"><a href="#cb66-11" aria-hidden="true" tabindex="-1"></a>            nn.PReLU(),</span>
<span id="cb66-12"><a href="#cb66-12" aria-hidden="true" tabindex="-1"></a>            nn.Dropout(<span class="fl">0.5</span>),</span>
<span id="cb66-13"><a href="#cb66-13" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">1024</span>, num_classes))</span>
<span id="cb66-14"><a href="#cb66-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb66-15"><a href="#cb66-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb66-16"><a href="#cb66-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> <span class="va">self</span>.efficientnet_v2_m(x)</span></code></pre></div>
</div>
<div class="cell code" id="f5f2f565" data-outputId="70fe27a3-76fb-4f37-b298-55a56d50fbfb">
<div class="sourceCode" id="cb67"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a>efficientnet_v2_m_v2 <span class="op">=</span> EfficientNetV2(num_classes<span class="op">=</span><span class="dv">10</span>)</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>efficientnet_v2_m_v2 <span class="op">=</span> efficientnet_v2_m_v2.to(device)</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a>summary(efficientnet_v2_m_v2, input_size<span class="op">=</span>input_size)</span></code></pre></div>
<div class="output stream stdout">
<pre><code>----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1          [-1, 128, 56, 56]           6,272
       LayerNorm2d-2          [-1, 128, 56, 56]             256
            Conv2d-3          [-1, 128, 56, 56]           6,400
           Permute-4          [-1, 56, 56, 128]               0
         LayerNorm-5          [-1, 56, 56, 128]             256
            Linear-6          [-1, 56, 56, 512]          66,048
              GELU-7          [-1, 56, 56, 512]               0
            Linear-8          [-1, 56, 56, 128]          65,664
           Permute-9          [-1, 128, 56, 56]               0
  StochasticDepth-10          [-1, 128, 56, 56]               0
          CNBlock-11          [-1, 128, 56, 56]               0
           Conv2d-12          [-1, 128, 56, 56]           6,400
          Permute-13          [-1, 56, 56, 128]               0
        LayerNorm-14          [-1, 56, 56, 128]             256
           Linear-15          [-1, 56, 56, 512]          66,048
             GELU-16          [-1, 56, 56, 512]               0
           Linear-17          [-1, 56, 56, 128]          65,664
          Permute-18          [-1, 128, 56, 56]               0
  StochasticDepth-19          [-1, 128, 56, 56]               0
          CNBlock-20          [-1, 128, 56, 56]               0
           Conv2d-21          [-1, 128, 56, 56]           6,400
          Permute-22          [-1, 56, 56, 128]               0
        LayerNorm-23          [-1, 56, 56, 128]             256
           Linear-24          [-1, 56, 56, 512]          66,048
             GELU-25          [-1, 56, 56, 512]               0
           Linear-26          [-1, 56, 56, 128]          65,664
          Permute-27          [-1, 128, 56, 56]               0
  StochasticDepth-28          [-1, 128, 56, 56]               0
          CNBlock-29          [-1, 128, 56, 56]               0
      LayerNorm2d-30          [-1, 128, 56, 56]             256
           Conv2d-31          [-1, 256, 28, 28]         131,328
           Conv2d-32          [-1, 256, 28, 28]          12,800
          Permute-33          [-1, 28, 28, 256]               0
        LayerNorm-34          [-1, 28, 28, 256]             512
           Linear-35         [-1, 28, 28, 1024]         263,168
             GELU-36         [-1, 28, 28, 1024]               0
           Linear-37          [-1, 28, 28, 256]         262,400
          Permute-38          [-1, 256, 28, 28]               0
  StochasticDepth-39          [-1, 256, 28, 28]               0
          CNBlock-40          [-1, 256, 28, 28]               0
           Conv2d-41          [-1, 256, 28, 28]          12,800
          Permute-42          [-1, 28, 28, 256]               0
        LayerNorm-43          [-1, 28, 28, 256]             512
           Linear-44         [-1, 28, 28, 1024]         263,168
             GELU-45         [-1, 28, 28, 1024]               0
           Linear-46          [-1, 28, 28, 256]         262,400
          Permute-47          [-1, 256, 28, 28]               0
  StochasticDepth-48          [-1, 256, 28, 28]               0
          CNBlock-49          [-1, 256, 28, 28]               0
           Conv2d-50          [-1, 256, 28, 28]          12,800
          Permute-51          [-1, 28, 28, 256]               0
        LayerNorm-52          [-1, 28, 28, 256]             512
           Linear-53         [-1, 28, 28, 1024]         263,168
             GELU-54         [-1, 28, 28, 1024]               0
           Linear-55          [-1, 28, 28, 256]         262,400
          Permute-56          [-1, 256, 28, 28]               0
  StochasticDepth-57          [-1, 256, 28, 28]               0
          CNBlock-58          [-1, 256, 28, 28]               0
      LayerNorm2d-59          [-1, 256, 28, 28]             512
           Conv2d-60          [-1, 512, 14, 14]         524,800
           Conv2d-61          [-1, 512, 14, 14]          25,600
          Permute-62          [-1, 14, 14, 512]               0
        LayerNorm-63          [-1, 14, 14, 512]           1,024
           Linear-64         [-1, 14, 14, 2048]       1,050,624
             GELU-65         [-1, 14, 14, 2048]               0
           Linear-66          [-1, 14, 14, 512]       1,049,088
          Permute-67          [-1, 512, 14, 14]               0
  StochasticDepth-68          [-1, 512, 14, 14]               0
          CNBlock-69          [-1, 512, 14, 14]               0
           Conv2d-70          [-1, 512, 14, 14]          25,600
          Permute-71          [-1, 14, 14, 512]               0
        LayerNorm-72          [-1, 14, 14, 512]           1,024
           Linear-73         [-1, 14, 14, 2048]       1,050,624
             GELU-74         [-1, 14, 14, 2048]               0
           Linear-75          [-1, 14, 14, 512]       1,049,088
          Permute-76          [-1, 512, 14, 14]               0
  StochasticDepth-77          [-1, 512, 14, 14]               0
          CNBlock-78          [-1, 512, 14, 14]               0
           Conv2d-79          [-1, 512, 14, 14]          25,600
          Permute-80          [-1, 14, 14, 512]               0
        LayerNorm-81          [-1, 14, 14, 512]           1,024
           Linear-82         [-1, 14, 14, 2048]       1,050,624
             GELU-83         [-1, 14, 14, 2048]               0
           Linear-84          [-1, 14, 14, 512]       1,049,088
          Permute-85          [-1, 512, 14, 14]               0
  StochasticDepth-86          [-1, 512, 14, 14]               0
          CNBlock-87          [-1, 512, 14, 14]               0
           Conv2d-88          [-1, 512, 14, 14]          25,600
          Permute-89          [-1, 14, 14, 512]               0
        LayerNorm-90          [-1, 14, 14, 512]           1,024
           Linear-91         [-1, 14, 14, 2048]       1,050,624
             GELU-92         [-1, 14, 14, 2048]               0
           Linear-93          [-1, 14, 14, 512]       1,049,088
          Permute-94          [-1, 512, 14, 14]               0
  StochasticDepth-95          [-1, 512, 14, 14]               0
          CNBlock-96          [-1, 512, 14, 14]               0
           Conv2d-97          [-1, 512, 14, 14]          25,600
          Permute-98          [-1, 14, 14, 512]               0
        LayerNorm-99          [-1, 14, 14, 512]           1,024
          Linear-100         [-1, 14, 14, 2048]       1,050,624
            GELU-101         [-1, 14, 14, 2048]               0
          Linear-102          [-1, 14, 14, 512]       1,049,088
         Permute-103          [-1, 512, 14, 14]               0
 StochasticDepth-104          [-1, 512, 14, 14]               0
         CNBlock-105          [-1, 512, 14, 14]               0
          Conv2d-106          [-1, 512, 14, 14]          25,600
         Permute-107          [-1, 14, 14, 512]               0
       LayerNorm-108          [-1, 14, 14, 512]           1,024
          Linear-109         [-1, 14, 14, 2048]       1,050,624
            GELU-110         [-1, 14, 14, 2048]               0
          Linear-111          [-1, 14, 14, 512]       1,049,088
         Permute-112          [-1, 512, 14, 14]               0
 StochasticDepth-113          [-1, 512, 14, 14]               0
         CNBlock-114          [-1, 512, 14, 14]               0
          Conv2d-115          [-1, 512, 14, 14]          25,600
         Permute-116          [-1, 14, 14, 512]               0
       LayerNorm-117          [-1, 14, 14, 512]           1,024
          Linear-118         [-1, 14, 14, 2048]       1,050,624
            GELU-119         [-1, 14, 14, 2048]               0
          Linear-120          [-1, 14, 14, 512]       1,049,088
         Permute-121          [-1, 512, 14, 14]               0
 StochasticDepth-122          [-1, 512, 14, 14]               0
         CNBlock-123          [-1, 512, 14, 14]               0
          Conv2d-124          [-1, 512, 14, 14]          25,600
         Permute-125          [-1, 14, 14, 512]               0
       LayerNorm-126          [-1, 14, 14, 512]           1,024
          Linear-127         [-1, 14, 14, 2048]       1,050,624
            GELU-128         [-1, 14, 14, 2048]               0
          Linear-129          [-1, 14, 14, 512]       1,049,088
         Permute-130          [-1, 512, 14, 14]               0
 StochasticDepth-131          [-1, 512, 14, 14]               0
         CNBlock-132          [-1, 512, 14, 14]               0
          Conv2d-133          [-1, 512, 14, 14]          25,600
         Permute-134          [-1, 14, 14, 512]               0
       LayerNorm-135          [-1, 14, 14, 512]           1,024
          Linear-136         [-1, 14, 14, 2048]       1,050,624
            GELU-137         [-1, 14, 14, 2048]               0
          Linear-138          [-1, 14, 14, 512]       1,049,088
         Permute-139          [-1, 512, 14, 14]               0
 StochasticDepth-140          [-1, 512, 14, 14]               0
         CNBlock-141          [-1, 512, 14, 14]               0
          Conv2d-142          [-1, 512, 14, 14]          25,600
         Permute-143          [-1, 14, 14, 512]               0
       LayerNorm-144          [-1, 14, 14, 512]           1,024
          Linear-145         [-1, 14, 14, 2048]       1,050,624
            GELU-146         [-1, 14, 14, 2048]               0
          Linear-147          [-1, 14, 14, 512]       1,049,088
         Permute-148          [-1, 512, 14, 14]               0
 StochasticDepth-149          [-1, 512, 14, 14]               0
         CNBlock-150          [-1, 512, 14, 14]               0
          Conv2d-151          [-1, 512, 14, 14]          25,600
         Permute-152          [-1, 14, 14, 512]               0
       LayerNorm-153          [-1, 14, 14, 512]           1,024
          Linear-154         [-1, 14, 14, 2048]       1,050,624
            GELU-155         [-1, 14, 14, 2048]               0
          Linear-156          [-1, 14, 14, 512]       1,049,088
         Permute-157          [-1, 512, 14, 14]               0
 StochasticDepth-158          [-1, 512, 14, 14]               0
         CNBlock-159          [-1, 512, 14, 14]               0
          Conv2d-160          [-1, 512, 14, 14]          25,600
         Permute-161          [-1, 14, 14, 512]               0
       LayerNorm-162          [-1, 14, 14, 512]           1,024
          Linear-163         [-1, 14, 14, 2048]       1,050,624
            GELU-164         [-1, 14, 14, 2048]               0
          Linear-165          [-1, 14, 14, 512]       1,049,088
         Permute-166          [-1, 512, 14, 14]               0
 StochasticDepth-167          [-1, 512, 14, 14]               0
         CNBlock-168          [-1, 512, 14, 14]               0
          Conv2d-169          [-1, 512, 14, 14]          25,600
         Permute-170          [-1, 14, 14, 512]               0
       LayerNorm-171          [-1, 14, 14, 512]           1,024
          Linear-172         [-1, 14, 14, 2048]       1,050,624
            GELU-173         [-1, 14, 14, 2048]               0
          Linear-174          [-1, 14, 14, 512]       1,049,088
         Permute-175          [-1, 512, 14, 14]               0
 StochasticDepth-176          [-1, 512, 14, 14]               0
         CNBlock-177          [-1, 512, 14, 14]               0
          Conv2d-178          [-1, 512, 14, 14]          25,600
         Permute-179          [-1, 14, 14, 512]               0
       LayerNorm-180          [-1, 14, 14, 512]           1,024
          Linear-181         [-1, 14, 14, 2048]       1,050,624
            GELU-182         [-1, 14, 14, 2048]               0
          Linear-183          [-1, 14, 14, 512]       1,049,088
         Permute-184          [-1, 512, 14, 14]               0
 StochasticDepth-185          [-1, 512, 14, 14]               0
         CNBlock-186          [-1, 512, 14, 14]               0
          Conv2d-187          [-1, 512, 14, 14]          25,600
         Permute-188          [-1, 14, 14, 512]               0
       LayerNorm-189          [-1, 14, 14, 512]           1,024
          Linear-190         [-1, 14, 14, 2048]       1,050,624
            GELU-191         [-1, 14, 14, 2048]               0
          Linear-192          [-1, 14, 14, 512]       1,049,088
         Permute-193          [-1, 512, 14, 14]               0
 StochasticDepth-194          [-1, 512, 14, 14]               0
         CNBlock-195          [-1, 512, 14, 14]               0
          Conv2d-196          [-1, 512, 14, 14]          25,600
         Permute-197          [-1, 14, 14, 512]               0
       LayerNorm-198          [-1, 14, 14, 512]           1,024
          Linear-199         [-1, 14, 14, 2048]       1,050,624
            GELU-200         [-1, 14, 14, 2048]               0
          Linear-201          [-1, 14, 14, 512]       1,049,088
         Permute-202          [-1, 512, 14, 14]               0
 StochasticDepth-203          [-1, 512, 14, 14]               0
         CNBlock-204          [-1, 512, 14, 14]               0
          Conv2d-205          [-1, 512, 14, 14]          25,600
         Permute-206          [-1, 14, 14, 512]               0
       LayerNorm-207          [-1, 14, 14, 512]           1,024
          Linear-208         [-1, 14, 14, 2048]       1,050,624
            GELU-209         [-1, 14, 14, 2048]               0
          Linear-210          [-1, 14, 14, 512]       1,049,088
         Permute-211          [-1, 512, 14, 14]               0
 StochasticDepth-212          [-1, 512, 14, 14]               0
         CNBlock-213          [-1, 512, 14, 14]               0
          Conv2d-214          [-1, 512, 14, 14]          25,600
         Permute-215          [-1, 14, 14, 512]               0
       LayerNorm-216          [-1, 14, 14, 512]           1,024
          Linear-217         [-1, 14, 14, 2048]       1,050,624
            GELU-218         [-1, 14, 14, 2048]               0
          Linear-219          [-1, 14, 14, 512]       1,049,088
         Permute-220          [-1, 512, 14, 14]               0
 StochasticDepth-221          [-1, 512, 14, 14]               0
         CNBlock-222          [-1, 512, 14, 14]               0
          Conv2d-223          [-1, 512, 14, 14]          25,600
         Permute-224          [-1, 14, 14, 512]               0
       LayerNorm-225          [-1, 14, 14, 512]           1,024
          Linear-226         [-1, 14, 14, 2048]       1,050,624
            GELU-227         [-1, 14, 14, 2048]               0
          Linear-228          [-1, 14, 14, 512]       1,049,088
         Permute-229          [-1, 512, 14, 14]               0
 StochasticDepth-230          [-1, 512, 14, 14]               0
         CNBlock-231          [-1, 512, 14, 14]               0
          Conv2d-232          [-1, 512, 14, 14]          25,600
         Permute-233          [-1, 14, 14, 512]               0
       LayerNorm-234          [-1, 14, 14, 512]           1,024
          Linear-235         [-1, 14, 14, 2048]       1,050,624
            GELU-236         [-1, 14, 14, 2048]               0
          Linear-237          [-1, 14, 14, 512]       1,049,088
         Permute-238          [-1, 512, 14, 14]               0
 StochasticDepth-239          [-1, 512, 14, 14]               0
         CNBlock-240          [-1, 512, 14, 14]               0
          Conv2d-241          [-1, 512, 14, 14]          25,600
         Permute-242          [-1, 14, 14, 512]               0
       LayerNorm-243          [-1, 14, 14, 512]           1,024
          Linear-244         [-1, 14, 14, 2048]       1,050,624
            GELU-245         [-1, 14, 14, 2048]               0
          Linear-246          [-1, 14, 14, 512]       1,049,088
         Permute-247          [-1, 512, 14, 14]               0
 StochasticDepth-248          [-1, 512, 14, 14]               0
         CNBlock-249          [-1, 512, 14, 14]               0
          Conv2d-250          [-1, 512, 14, 14]          25,600
         Permute-251          [-1, 14, 14, 512]               0
       LayerNorm-252          [-1, 14, 14, 512]           1,024
          Linear-253         [-1, 14, 14, 2048]       1,050,624
            GELU-254         [-1, 14, 14, 2048]               0
          Linear-255          [-1, 14, 14, 512]       1,049,088
         Permute-256          [-1, 512, 14, 14]               0
 StochasticDepth-257          [-1, 512, 14, 14]               0
         CNBlock-258          [-1, 512, 14, 14]               0
          Conv2d-259          [-1, 512, 14, 14]          25,600
         Permute-260          [-1, 14, 14, 512]               0
       LayerNorm-261          [-1, 14, 14, 512]           1,024
          Linear-262         [-1, 14, 14, 2048]       1,050,624
            GELU-263         [-1, 14, 14, 2048]               0
          Linear-264          [-1, 14, 14, 512]       1,049,088
         Permute-265          [-1, 512, 14, 14]               0
 StochasticDepth-266          [-1, 512, 14, 14]               0
         CNBlock-267          [-1, 512, 14, 14]               0
          Conv2d-268          [-1, 512, 14, 14]          25,600
         Permute-269          [-1, 14, 14, 512]               0
       LayerNorm-270          [-1, 14, 14, 512]           1,024
          Linear-271         [-1, 14, 14, 2048]       1,050,624
            GELU-272         [-1, 14, 14, 2048]               0
          Linear-273          [-1, 14, 14, 512]       1,049,088
         Permute-274          [-1, 512, 14, 14]               0
 StochasticDepth-275          [-1, 512, 14, 14]               0
         CNBlock-276          [-1, 512, 14, 14]               0
          Conv2d-277          [-1, 512, 14, 14]          25,600
         Permute-278          [-1, 14, 14, 512]               0
       LayerNorm-279          [-1, 14, 14, 512]           1,024
          Linear-280         [-1, 14, 14, 2048]       1,050,624
            GELU-281         [-1, 14, 14, 2048]               0
          Linear-282          [-1, 14, 14, 512]       1,049,088
         Permute-283          [-1, 512, 14, 14]               0
 StochasticDepth-284          [-1, 512, 14, 14]               0
         CNBlock-285          [-1, 512, 14, 14]               0
          Conv2d-286          [-1, 512, 14, 14]          25,600
         Permute-287          [-1, 14, 14, 512]               0
       LayerNorm-288          [-1, 14, 14, 512]           1,024
          Linear-289         [-1, 14, 14, 2048]       1,050,624
            GELU-290         [-1, 14, 14, 2048]               0
          Linear-291          [-1, 14, 14, 512]       1,049,088
         Permute-292          [-1, 512, 14, 14]               0
 StochasticDepth-293          [-1, 512, 14, 14]               0
         CNBlock-294          [-1, 512, 14, 14]               0
          Conv2d-295          [-1, 512, 14, 14]          25,600
         Permute-296          [-1, 14, 14, 512]               0
       LayerNorm-297          [-1, 14, 14, 512]           1,024
          Linear-298         [-1, 14, 14, 2048]       1,050,624
            GELU-299         [-1, 14, 14, 2048]               0
          Linear-300          [-1, 14, 14, 512]       1,049,088
         Permute-301          [-1, 512, 14, 14]               0
 StochasticDepth-302          [-1, 512, 14, 14]               0
         CNBlock-303          [-1, 512, 14, 14]               0
     LayerNorm2d-304          [-1, 512, 14, 14]           1,024
          Conv2d-305           [-1, 1024, 7, 7]       2,098,176
          Conv2d-306           [-1, 1024, 7, 7]          51,200
         Permute-307           [-1, 7, 7, 1024]               0
       LayerNorm-308           [-1, 7, 7, 1024]           2,048
          Linear-309           [-1, 7, 7, 4096]       4,198,400
            GELU-310           [-1, 7, 7, 4096]               0
          Linear-311           [-1, 7, 7, 1024]       4,195,328
         Permute-312           [-1, 1024, 7, 7]               0
 StochasticDepth-313           [-1, 1024, 7, 7]               0
         CNBlock-314           [-1, 1024, 7, 7]               0
          Conv2d-315           [-1, 1024, 7, 7]          51,200
         Permute-316           [-1, 7, 7, 1024]               0
       LayerNorm-317           [-1, 7, 7, 1024]           2,048
          Linear-318           [-1, 7, 7, 4096]       4,198,400
            GELU-319           [-1, 7, 7, 4096]               0
          Linear-320           [-1, 7, 7, 1024]       4,195,328
         Permute-321           [-1, 1024, 7, 7]               0
 StochasticDepth-322           [-1, 1024, 7, 7]               0
         CNBlock-323           [-1, 1024, 7, 7]               0
          Conv2d-324           [-1, 1024, 7, 7]          51,200
         Permute-325           [-1, 7, 7, 1024]               0
       LayerNorm-326           [-1, 7, 7, 1024]           2,048
          Linear-327           [-1, 7, 7, 4096]       4,198,400
            GELU-328           [-1, 7, 7, 4096]               0
          Linear-329           [-1, 7, 7, 1024]       4,195,328
         Permute-330           [-1, 1024, 7, 7]               0
 StochasticDepth-331           [-1, 1024, 7, 7]               0
         CNBlock-332           [-1, 1024, 7, 7]               0
AdaptiveAvgPool2d-333           [-1, 1024, 1, 1]               0
     LayerNorm2d-334           [-1, 1024, 1, 1]           2,048
         Flatten-335                 [-1, 1024]               0
         Dropout-336                 [-1, 1024]               0
          Linear-337                 [-1, 1024]       1,049,600
     BatchNorm1d-338                 [-1, 1024]           2,048
           PReLU-339                 [-1, 1024]               1
         Dropout-340                 [-1, 1024]               0
          Linear-341                   [-1, 10]          10,250
        ConvNeXt-342                   [-1, 10]               0
================================================================
Total params: 88,610,315
Trainable params: 1,061,899
Non-trainable params: 87,548,416
----------------------------------------------------------------
Input size (MB): 0.57
Forward/backward pass size (MB): 548.25
Params size (MB): 338.02
Estimated Total Size (MB): 886.85
----------------------------------------------------------------
</code></pre>
</div>
</div>
<div class="cell code" id="cfca25e3" data-outputId="c3f52e8b-fd67-4b5a-d868-89a4a80d521a">
<div class="sourceCode" id="cb69"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>trainer_efficientnet_v2_m_v2_lion <span class="op">=</span> ClassificationTrainer(model<span class="op">=</span>efficientnet_v2_m_v2,</span>
<span id="cb69-2"><a href="#cb69-2" aria-hidden="true" tabindex="-1"></a>                                         name_optimizer<span class="op">=</span><span class="st">&#39;Lion&#39;</span>,</span>
<span id="cb69-3"><a href="#cb69-3" aria-hidden="true" tabindex="-1"></a>                                         scheduler<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb69-4"><a href="#cb69-4" aria-hidden="true" tabindex="-1"></a>                                         train_dataset<span class="op">=</span>train_dataset,</span>
<span id="cb69-5"><a href="#cb69-5" aria-hidden="true" tabindex="-1"></a>                                         test_dataset<span class="op">=</span>test_dataset,</span>
<span id="cb69-6"><a href="#cb69-6" aria-hidden="true" tabindex="-1"></a>                                         batch_size<span class="op">=</span><span class="dv">128</span>,</span>
<span id="cb69-7"><a href="#cb69-7" aria-hidden="true" tabindex="-1"></a>                                         learning_rate<span class="op">=</span><span class="fl">1e-4</span>,</span>
<span id="cb69-8"><a href="#cb69-8" aria-hidden="true" tabindex="-1"></a>                                         coef<span class="op">=</span><span class="fl">0.85</span>,</span>
<span id="cb69-9"><a href="#cb69-9" aria-hidden="true" tabindex="-1"></a>                                         step_size<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb69-10"><a href="#cb69-10" aria-hidden="true" tabindex="-1"></a>                                         num_epochs<span class="op">=</span><span class="dv">50</span>)</span>
<span id="cb69-11"><a href="#cb69-11" aria-hidden="true" tabindex="-1"></a>trainer_efficientnet_v2_m_v2_lion.train()</span>
<span id="cb69-12"><a href="#cb69-12" aria-hidden="true" tabindex="-1"></a>trainer_efficientnet_v2_m_v2_lion.plot_training_history()</span></code></pre></div>
<div class="output stream stdout">
<pre><code>Обучение завершено!!!
Best accuracy: 0.9455
</code></pre>
</div>
<div class="output display_data">
<p><img src="8db968a7243c38687a31b03890a714ad49f6347e.png" /></p>
</div>
</div>
<div class="cell markdown" id="69ecf96b">
<p>Практически одинаковые результаты были получены, за исключением того случая, где мы усложнили слой классификации. В этот раз модель уже с первой эпохи показала результат в 0.94, в то время как первой модели потребовалось около 3 эпох.</p>
<p>Дополнительно, эксперименты с аугментацией данных могут улучшить результаты. Вероятно, модель является достаточно мощной для данного датасета, что подтверждается низким значением функции потерь.</p>
</div>
<div class="cell code" id="64d5fbec" data-outputId="358f6a1b-df09-4013-fc96-ebf712613c80">
<div class="sourceCode" id="cb71"><pre class="sourceCode python"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> [</span>
<span id="cb71-2"><a href="#cb71-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Alexnet Lion с freeze слоев&#39;</span>, <span class="st">&#39;Alexnet Adamw с freeze слоев&#39;</span>, <span class="st">&#39;Alexnet Lion finetuning&#39;</span>, <span class="st">&#39;Alexnet Adamw finetuning&#39;</span>,</span>
<span id="cb71-3"><a href="#cb71-3" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;Resnet34 Lion с freeze слоев&#39;</span>, <span class="st">&#39;Resnet34 Adamw с freeze слоев&#39;</span>, <span class="st">&#39;Resnet34 Lion finetuning&#39;</span>, <span class="st">&#39;Resnet34 Adamw finetuning&#39;</span>,</span>
<span id="cb71-4"><a href="#cb71-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;MobileNet V2 Lion с freeze слоев&#39;</span>, <span class="st">&#39;MobileNet V2 Adamw с freeze слоев&#39;</span>, <span class="st">&#39;MobileNet V2 Lion finetuning&#39;</span>, <span class="st">&#39;MobileNet V2 Adamw finetuning&#39;</span>,</span>
<span id="cb71-5"><a href="#cb71-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&#39;EfficientNetv2 Lion simpleclassifier слоев&#39;</span>, <span class="st">&#39;EfficientNetv2 Lion hardclassifierслоев&#39;</span></span>
<span id="cb71-6"><a href="#cb71-6" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb71-7"><a href="#cb71-7" aria-hidden="true" tabindex="-1"></a>accuracies <span class="op">=</span> [</span>
<span id="cb71-8"><a href="#cb71-8" aria-hidden="true" tabindex="-1"></a>    <span class="fl">0.8021</span>, <span class="fl">0.7865</span>, <span class="fl">0.9056</span>, <span class="fl">0.9244</span>,</span>
<span id="cb71-9"><a href="#cb71-9" aria-hidden="true" tabindex="-1"></a>    <span class="fl">0.8284</span>, <span class="fl">0.815</span>, <span class="fl">0.9552</span>, <span class="fl">0.9637</span>,</span>
<span id="cb71-10"><a href="#cb71-10" aria-hidden="true" tabindex="-1"></a>    <span class="fl">0.7357</span>, <span class="fl">0.6835</span>, <span class="fl">0.9496</span>, <span class="fl">0.9389</span>,</span>
<span id="cb71-11"><a href="#cb71-11" aria-hidden="true" tabindex="-1"></a>    <span class="fl">0.9484</span>, <span class="fl">0.9455</span></span>
<span id="cb71-12"><a href="#cb71-12" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb71-13"><a href="#cb71-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-14"><a href="#cb71-14" aria-hidden="true" tabindex="-1"></a>sorted_indices <span class="op">=</span> <span class="bu">sorted</span>(<span class="bu">range</span>(<span class="bu">len</span>(accuracies)), key<span class="op">=</span><span class="kw">lambda</span> k: accuracies[k], reverse<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb71-15"><a href="#cb71-15" aria-hidden="true" tabindex="-1"></a>models_sorted <span class="op">=</span> [models[i] <span class="cf">for</span> i <span class="kw">in</span> sorted_indices]</span>
<span id="cb71-16"><a href="#cb71-16" aria-hidden="true" tabindex="-1"></a>accuracies_sorted <span class="op">=</span> [accuracies[i] <span class="cf">for</span> i <span class="kw">in</span> sorted_indices]</span>
<span id="cb71-17"><a href="#cb71-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-18"><a href="#cb71-18" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">16</span>, <span class="dv">8</span>))</span>
<span id="cb71-19"><a href="#cb71-19" aria-hidden="true" tabindex="-1"></a>bars <span class="op">=</span> plt.bar(models_sorted, accuracies_sorted, color<span class="op">=</span>[<span class="st">&#39;blue&#39;</span>, <span class="st">&#39;orange&#39;</span>, <span class="st">&#39;green&#39;</span>, <span class="st">&#39;red&#39;</span>, <span class="st">&#39;purple&#39;</span>, <span class="st">&#39;brown&#39;</span>, <span class="st">&#39;pink&#39;</span>, <span class="st">&#39;gray&#39;</span>])</span>
<span id="cb71-20"><a href="#cb71-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-21"><a href="#cb71-21" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> bar, accuracy <span class="kw">in</span> <span class="bu">zip</span>(bars, accuracies_sorted):</span>
<span id="cb71-22"><a href="#cb71-22" aria-hidden="true" tabindex="-1"></a>    plt.text(bar.get_x() <span class="op">+</span> bar.get_width() <span class="op">/</span> <span class="dv">2</span>, bar.get_height() <span class="op">+</span> <span class="fl">0.01</span>, <span class="ss">f&#39;</span><span class="sc">{</span>accuracy<span class="sc">:.4f}</span><span class="ss">&#39;</span>, ha<span class="op">=</span><span class="st">&#39;center&#39;</span>, fontsize<span class="op">=</span><span class="dv">8</span>)</span>
<span id="cb71-23"><a href="#cb71-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-24"><a href="#cb71-24" aria-hidden="true" tabindex="-1"></a>plt.xticks(rotation<span class="op">=</span><span class="dv">45</span>, ha<span class="op">=</span><span class="st">&#39;right&#39;</span>)</span>
<span id="cb71-25"><a href="#cb71-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-26"><a href="#cb71-26" aria-hidden="true" tabindex="-1"></a>plt.xlabel(<span class="st">&#39;Модели&#39;</span>)</span>
<span id="cb71-27"><a href="#cb71-27" aria-hidden="true" tabindex="-1"></a>plt.ylabel(<span class="st">&#39;Точность&#39;</span>)</span>
<span id="cb71-28"><a href="#cb71-28" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">&#39;Сравнение точности различных моделей (отсортировано)&#39;</span>)</span>
<span id="cb71-29"><a href="#cb71-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-30"><a href="#cb71-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb71-31"><a href="#cb71-31" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb71-32"><a href="#cb71-32" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
<div class="output display_data">
<p><img src="0902f13de78458fde28556621c28806ff3d7499b.png" /></p>
</div>
</div>
<div class="cell markdown" id="78892a20">
<p>Исходя из графика, мы видим следующие результаты точности для различных моделей:</p>
<ol>
<li><p><strong>Resnet34 Adamw finetuning</strong> демонстрирует самую высокую точность (0.9637) среди всех моделей, когда используется Adamw для fine-tuning.</p></li>
<li><p><strong>Resnet34 Lion finetuning</strong> и <strong>EfficientNetv2 Lion simpleclassifier слоев</strong> также показывают высокую точность (0.9552 и 0.9484 соответственно) после fine-tuning.</p></li>
<li><p>Модели <strong>Alexnet Lion finetuning</strong> и <strong>Alexnet Adamw finetuning</strong> имеют более низкую, но все равно впечатляющую точность после fine-tuning (0.9056 и 0.9244 соответственно).</p></li>
<li><p>Среди моделей с замороженными слоями, <strong>Resnet34 Lion с freeze слоев</strong> и <strong>Alexnet Lion с freeze слоев</strong> демонстрируют более высокую точность (0.8284 и 0.8021 соответственно) по сравнению с аналогичными моделями с использованием Adamw.</p></li>
<li><p>Также в данной работе опробовали новый оптимайзер Lion, который порой показывал довольно высокую скорость, как обучения, так и точности.</p></li>
</ol>
<p>В данной работе рассмотрели модели с 2012 по 2020 год, можно сказать, что есть тенденция на уменьшения кол-во параметров для более высокой скорости работы моделей. Мы заметили как ResNet34 и MobileNetV2 показали почти одни и те же результаты, только разница в обучаемых параметрах была в 10 раз.</p>
</div>
</body>
</html>
